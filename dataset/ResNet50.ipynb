{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0948c5-62cd-430a-bf5f-47f42f49d790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea68aa4-b475-4e40-8c53-d291dd748477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18345 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 1702\n",
      "Label: Tomato___Early_blight, Number of Images: 1920\n",
      "Label: Tomato___Late_blight, Number of Images: 1851\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 1882\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 1745\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 1741\n",
      "Label: Tomato___Target_Spot, Number of Images: 1827\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 1961\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 1790\n",
      "Label: Tomato___healthy, Number of Images: 1926\n"
     ]
    }
   ],
   "source": [
    "# get train \n",
    "\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"train\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'train/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(500, 700))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('train/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2738ef-4693-49df-b8f0-99fe4f906523",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4585 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 425\n",
      "Label: Tomato___Early_blight, Number of Images: 480\n",
      "Label: Tomato___Late_blight, Number of Images: 463\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 470\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 436\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 435\n",
      "Label: Tomato___Target_Spot, Number of Images: 457\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 490\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 448\n",
      "Label: Tomato___healthy, Number of Images: 481\n"
     ]
    }
   ],
   "source": [
    "# get validation \n",
    "\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"valid\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "val_image_urls = []\n",
    "val_labels = []\n",
    "val_images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'valid/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(50, 90))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('valid/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        val_image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        val_labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(val_image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67969380-14e2-4844-b1ce-5b087143455f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are 10 available classes: ['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
      " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
      " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
      " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
      " 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "CLASS_NAMES = np.array(\n",
    "    [\"Tomato___Bacterial_spot\", \n",
    "\"Tomato___Early_blight\", \n",
    "\"Tomato___Late_blight\",\n",
    "\"Tomato___Leaf_Mold\",\n",
    "\"Tomato___Septoria_leaf_spot\",\n",
    "\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "\"Tomato___Target_Spot\",\n",
    "\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "\"Tomato___Tomato_mosaic_virus\",\n",
    "\"Tomato___healthy\"]\n",
    ")\n",
    "\n",
    "print(f\"These are {len(CLASS_NAMES)} available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbcd0ce-6ba7-479b-85bc-7a82a9031bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Assuming image_urls, labels, val_image_urls, and val_labels are defined\n",
    "# CLASS_NAMES should also be defined as a list of class names\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def preprocess(file_path, label_str):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.math.equal(CLASS_NAMES, label_str)\n",
    "    label = tf.cast(label, tf.float32)  # Convert label to float32\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls))\n",
    "    if training:\n",
    "        dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "        dataset = dataset.cache().repeat()\n",
    "    else:\n",
    "        dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.cache().repeat(1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load training and validation datasets\n",
    "batch_size = 128\n",
    "SHUFFLE_BUFFER = 1024\n",
    "train_dataset = load_dataset(image_urls, labels, batch_size, training=True)\n",
    "val_dataset = load_dataset(val_image_urls, val_labels, batch_size, training=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f0f199-61a0-40ae-a6ea-45982280b735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "SHUFFLE_BUFFER = 1000 \n",
    "batch_size = 128\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def read_and_preprocess(file_path, label_str, random_augment=False):\n",
    "    if random_augment:\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        # image = tf.image.random_brightness(image, MAX_DELTA)\n",
    "        # image = tf.image.random_contrast(image, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "        image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    else: \n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.math.equal(CLASS_NAMES, label_str)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "def read_and_preprocess_with_augment(file_path, label_str):\n",
    "    return read_and_preprocess(file_path, label_str, random_augment=True)\n",
    "\n",
    "def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls)).cache()\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(len(image_urls))\n",
    "        dataset = dataset.map(read_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat()\n",
    "    else:\n",
    "        dataset = dataset.map(read_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat(1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dataset = load_dataset(image_urls, labels, batch_size, training=True)\n",
    "val_dataset = load_dataset(val_image_urls, val_labels, batch_size, training=False)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da9ecd-bda6-427f-94bf-ed1a278a130e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "114/143 [======================>.......] - ETA: 38s - loss: 1.1655 - accuracy: 0.6593"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(CLASS_NAMES), activation='softmax')(x)  # Adjust output layer to number of classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of ResNet50 base model\n",
    "\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0001, weight_decay = 0.0001), \n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(train_dataset,\n",
    "#                     epochs=10,  # Set the number of epochs as needed\n",
    "#                     steps_per_epoch=len(image_urls) // batch_size,\n",
    "#                     validation_data=val_dataset,\n",
    "#                     validation_steps=len(val_image_urls) // batch_size)\n",
    "\n",
    "# Unfreeze some layers and fine-tune the model\n",
    "for layer in base_model.layers[-32:]:  # Unfreeze the last 10 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001, weight_decay = 0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='../model/resnet_50_layers_cp.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=2,verbose=1,min_lr=0.0001)\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=20,  # Continue for more epochs if necessary\n",
    "                         steps_per_epoch=len(image_urls) // batch_size,\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=len(val_image_urls) // batch_size,\n",
    "                         callbacks = [early_stopping,reduce_lr, model_checkpoint]\n",
    "                        )\n",
    "\n",
    "\n",
    "# model.save('../model/resnet_50_layers_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ebc66cb-4856-45db-b46c-4f221c2f1824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Input, GlobalAveragePooling2D, Dense, MaxPooling2D\n",
    "from tensorflow.keras import callbacks, models\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, filters, kernel_size):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, filters, kernel_size, strides=(2, 2)):\n",
    "    filters1, filters2, filters3 = filters\n",
    "    \n",
    "    x = Conv2D(filters1, (1, 1), strides=strides)(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters2, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters3, (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides)(input_tensor)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet50(input_shape, classes):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolution and max-pooling\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    # First block\n",
    "    x = conv_block(x, [64, 64, 256], (3, 3), strides=(1, 1))\n",
    "    x = identity_block(x, [64, 64, 256], (3, 3))\n",
    "    x = identity_block(x, [64, 64, 256], (3, 3))\n",
    "    \n",
    "    # Second block\n",
    "    x = conv_block(x, [128, 128, 512], (3, 3))\n",
    "    x = identity_block(x, [128, 128, 512], (3, 3))\n",
    "    x = identity_block(x, [128, 128, 512], (3, 3))\n",
    "    x = identity_block(x, [128, 128, 512], (3, 3))\n",
    "    \n",
    "    # Third block\n",
    "    x = conv_block(x, [256, 256, 1024], (3, 3))\n",
    "    x = identity_block(x, [256, 256, 1024], (3, 3))\n",
    "    x = identity_block(x, [256, 256, 1024], (3, 3))\n",
    "    x = identity_block(x, [256, 256, 1024], (3, 3))\n",
    "    x = identity_block(x, [256, 256, 1024], (3, 3))\n",
    "    x = identity_block(x, [256, 256, 1024], (3, 3))\n",
    "    \n",
    "    # Fourth block\n",
    "    x = conv_block(x, [512, 512, 2048], (3, 3))\n",
    "    x = identity_block(x, [512, 512, 2048], (3, 3))\n",
    "    x = identity_block(x, [512, 512, 2048], (3, 3))\n",
    "    \n",
    "    # Global Average Pooling and output layer\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(img_input, x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e224296-ceb2-4c00-b7b0-0071f6f46249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 10:15:26.689845: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-26 10:15:26.689917: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-26 10:15:33.783536: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-06-26 10:15:33.783603: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55/573 [=>............................] - ETA: 10:21 - loss: 2.4696 - accuracy: 0.2859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m SHUFFLE_BUFFER \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_image_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(val_dataset, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_image_urls) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# resnet \n",
    "\n",
    "input_shape = (224, 224, 3)  # Adjust according to your image dimensions\n",
    "num_classes = len(CLASS_NAMES)\n",
    "\n",
    "# Build ResNet50 model\n",
    "model = resnet50(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define training parameters\n",
    "epochs = 32\n",
    "batch_size = 128\n",
    "SHUFFLE_BUFFER = 1024\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=len(image_urls) // batch_size,\n",
    "                    validation_data=val_dataset,\n",
    "                    validation_steps=len(val_image_urls) // batch_size)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_dataset, steps=len(val_image_urls) // batch_size)\n",
    "print(f'Validation accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5efa851-4bd2-42d3-95eb-ea5ef5063130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "base_model = ResNet50(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c621ea-b8b0-4909-a3dd-07010810c7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-12:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
