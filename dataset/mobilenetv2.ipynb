{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4N88SJ0PXWY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 03:22:39.403560: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def relu6(inputs):\n",
    "    '''\n",
    "        Performs the ReLU6 activation function for the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs for the activation function\n",
    "        Return:\n",
    "            Min value between the value of the regular ReLU function and 6\n",
    "    '''\n",
    "    \n",
    "    return K.relu(inputs,max_value=6)\n",
    "\n",
    "def bottleneck(inputs, t, alpha, num_filters, kernel_sz=(3,3),stride=(1,1),pad='same',residual=False,dropout=False,dropout_perc=0.1):    \n",
    "    '''\n",
    "        Performs the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs\n",
    "            t: the value used to increase the number of filters of the expansion stage\n",
    "            alpha: width multiplier that controls the number of filters of the output tensor\n",
    "            num_filters: number of filters of the output tensor\n",
    "            kernel_sz = kernel size of the filter\n",
    "            stride: stride of the kernel\n",
    "            pad: padding of the filter\n",
    "            residual: parameter that determine the sum of the input and output of the bottleneck stage\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero\n",
    "        Return:\n",
    "            x: the result of the bottleneck stage\n",
    "    '''    \n",
    "    \n",
    "    # Get the index of the input 4D tensor that represents the number of channels of the image\n",
    "    # -1 can also represent the last element of the tensor\n",
    "    channel_idx = 1 if K.image_data_format == 'channels_first' else -1\n",
    "    \n",
    "    # Number of filters for the expansion convolution\n",
    "    num_filters_exp = K.int_shape(inputs)[channel_idx] * t    \n",
    "    \n",
    "    # Number of filters of the projection convolution\n",
    "    num_filters_proj = int(num_filters * alpha)\n",
    "    \n",
    "    # Expansion layer\n",
    "    x = Conv2D(filters=num_filters_exp,kernel_size=(1,1),strides=(1,1),padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Depthwise convolution\n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Projection convolution\n",
    "    x = Conv2D(filters=num_filters_proj,kernel_size=(1,1),strides=(1,1),padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if (residual == True):\n",
    "        x = Add()([x,inputs])\n",
    "        \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def depthwise_block(inputs,stride,kernel_sz=(3,3),pad='same'):\n",
    "    '''\n",
    "        Function that performs the depthwise convolution\n",
    "        Inputs:\n",
    "            inputs:    the input shape of the depthwise convolution\n",
    "            kernel_sz: a tuple that indicates the size of the filtering kernel\n",
    "            stride:    a tuple that indicates the strides of the kernel\n",
    "        Return:\n",
    "            x: the result of the depthwise convolution\n",
    "    '''\n",
    "        \n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def pointwise_block(inputs,num_filters,alpha,kernel_sz=(1,1),stride=(1,1),pad='same',dropout=False,dropout_perc=0.1):\n",
    "    '''\n",
    "        Function that performs the pointwise convolution\n",
    "        Inputs:\n",
    "            inputs:      the input shape of the depthwise convolution\n",
    "            num_filters: number of filters to be used in the convolution\n",
    "            kernel_sz:   a tuple that indicates the size of the filtering kernel\n",
    "            stride:      a tuple that indicates the strides of the kernel\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero            \n",
    "        Return:\n",
    "            x: the result of the pointwise convolution\n",
    "    '''    \n",
    "    \n",
    "    # Number of filters based on width multiplier reported in the original paper\n",
    "    n_fil = int(num_filters * alpha)    \n",
    "    \n",
    "    x = Conv2D(filters=n_fil,kernel_size=kernel_sz,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNetV2_ex(input_shape, num_units, filters=32, kernel_sz=(3,3),stride=(2,2),alp=1,ro=1,dropout_perc=0.1):\n",
    "    input_shape = (int(input_shape[0] * ro), int(input_shape[1] * ro), input_shape[2])\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Regular convolution\n",
    "    x = Conv2D(filters=filters,kernel_size=kernel_sz,strides=stride)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    x = Dropout(dropout_perc)(x)\n",
    "\n",
    "    # First bottleneck convolution\n",
    "    x = bottleneck(x,t=1,alpha=alp,num_filters=16,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "\n",
    "    # Second bottleneck convolution (peformed 2 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(2,2),dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Third bottleneck convolution (peformed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fourth bottleneck convolution (performed 4 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fifth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Sixth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Seventh bottleneck convolution (performed 1 time)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=320,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Eigth layer (regular convolution)\n",
    "    x = Conv2D(filters=1280, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    # Pooling layer\n",
    "    # Pooling size correction due to the resolution multiplier parameter\n",
    "    pool_size = int(np.round(7*ro))\n",
    "    x = AveragePooling2D(padding='valid',pool_size=(pool_size,pool_size),strides=(1,1))(x)    \n",
    "    \n",
    "    x = Conv2D(filters=num_units,kernel_size=(1,1),strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    output = Reshape((num_units,))(Activation(activation='softmax')(x))\n",
    "    \n",
    "    return Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rO1uBKlDSMXH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "ro = 1\n",
    "img_size = 224\n",
    "target_sz = int(img_size * ro)\n",
    "batch_sz = 32\n",
    "epo = 100\n",
    "\n",
    "# image_generator = ImageDataGenerator(rotation_range=15,\n",
    "#                                       rescale=1./255,\n",
    "#                                       shear_range=0.2,\n",
    "#                                       zoom_range=0.1,\n",
    "#                                       horizontal_flip=True,\n",
    "#                                       fill_mode='nearest')\n",
    "# train_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Treinamento',\n",
    "#                                                      target_size=(target_sz,target_sz),\n",
    "#                                                      color_mode='rgb',\n",
    "#                                                      batch_size=batch_sz,\n",
    "#                                                      class_mode='categorical',\n",
    "#                                                      shuffle=True)\n",
    "\n",
    "# image_generator = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Teste',\n",
    "#                                                      target_size=(target_sz,target_sz),\n",
    "#                                                      color_mode='rgb',\n",
    "#                                                      batch_size=batch_sz,\n",
    "#                                                      class_mode='categorical',\n",
    "#                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6442 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 635\n",
      "Label: Tomato___Early_blight, Number of Images: 647\n",
      "Label: Tomato___Late_blight, Number of Images: 666\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 619\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 649\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 608\n",
      "Label: Tomato___Target_Spot, Number of Images: 642\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 673\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 614\n",
      "Label: Tomato___healthy, Number of Images: 689\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"train\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'train/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "label_limits = defaultdict(lambda: random.randint(600, 700))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('train/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        if label_counts[label] < label_limits[label]:\n",
    "            image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "            labels.append(label)\n",
    "            label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def load_dataset(csv_of_filenames, batch_size, training=True):\n",
    "#     dataset = (\n",
    "#         tf.data.TextLineDataset(filenames=csv_of_filenames)\n",
    "#         .map(decode_csv)\n",
    "#         .cache()\n",
    "#     )\n",
    "\n",
    "#     if training:\n",
    "#         dataset = (\n",
    "#             dataset.map(read_and_preprocess_with_augment)\n",
    "#             .shuffle(SHUFFLE_BUFFER)\n",
    "#             .repeat(count=None)\n",
    "#         )  # Indefinately.\n",
    "#     else:\n",
    "#         dataset = dataset.map(read_and_preprocess).repeat(\n",
    "#             count=1\n",
    "#         )  # Each photo used once.\n",
    "\n",
    "#     # Prefetch prepares the next set of batches while current batch is in use.\n",
    "#     return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# def load_data_from_gcs(image_urls):\n",
    "#     for url in image_urls[:10]:\n",
    "#         images.append(preprocess_image(url))\n",
    "#     return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images = load_data_from_gcs(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 958 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 94\n",
      "Label: Tomato___Early_blight, Number of Images: 93\n",
      "Label: Tomato___Late_blight, Number of Images: 91\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 95\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 97\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 91\n",
      "Label: Tomato___Target_Spot, Number of Images: 104\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 95\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 93\n",
      "Label: Tomato___healthy, Number of Images: 105\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"valid\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "val_image_urls = []\n",
    "val_labels = []\n",
    "val_images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'valid/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "label_limits = defaultdict(lambda: random.randint(90, 105))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('valid/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        if label_counts[label] < label_limits[label]:\n",
    "            val_image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "            val_labels.append(label)\n",
    "            label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(val_image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are 10 available classes: ['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
      " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
      " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
      " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
      " 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = np.array(\n",
    "    [\"Tomato___Bacterial_spot\", \n",
    "\"Tomato___Early_blight\", \n",
    "\"Tomato___Late_blight\",\n",
    "\"Tomato___Leaf_Mold\",\n",
    "\"Tomato___Septoria_leaf_spot\",\n",
    "\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "\"Tomato___Target_Spot\",\n",
    "\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "\"Tomato___Tomato_mosaic_virus\",\n",
    "\"Tomato___healthy\"]\n",
    ")\n",
    "\n",
    "print(f\"These are {len(CLASS_NAMES)} available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 03:22:49.810228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:49.813821: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:49.821034: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:49.824296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:49.827737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:49.831008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.447027: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.449180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.451361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.453343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.455394: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:50.457371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.822200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.825078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.827751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.829839: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.832331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.834340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13566 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2024-06-25 03:22:51.835352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 03:22:51.837363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13566 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "SHUFFLE_BUFFER = 1000 \n",
    "batch_size = 32\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def preprocess(file_path, label_str):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.math.equal(CLASS_NAMES, label_str)\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls))\n",
    "    if training:\n",
    "        dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "        dataset = dataset.repeat()\n",
    "    else:\n",
    "        dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat(1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dataset = load_dataset(image_urls, labels, batch_size, training=True)\n",
    "val_dataset = load_dataset(val_image_urls, val_labels, batch_size, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 03:22:52.137161: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [958]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 03:22:52.137478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [958]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (32, 224, 224, 3), Label: [[ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]]\n",
      "Image shape: (32, 224, 224, 3), Label: [[ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]\n",
      " [ True False False False False False False False False False]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming `dataset` is your tf.data.Dataset object\n",
    "for img_url, lbl in val_dataset.take(2):\n",
    "    print(f\"Image shape: {img_url.shape}, Label: {lbl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLALd9dcS0MM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Input, Model\n",
    "# from tensorflow.keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "# import numpy as np\n",
    "\n",
    "# VALIDATION_STEPS = 980 // 32\n",
    "\n",
    "# model_v2 = MobileNetV2_ex(input_shape=(224,224,3), num_units=10, alp=1, ro=1, dropout_perc=0.2)\n",
    "\n",
    "# optimizer = Adam(lr=0.001)\n",
    "\n",
    "# model_v2.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model_check_point_v2 = ModelCheckpoint(filepath='../model/model_mb_v2.hdf5',monitor='val_loss',verbose=1,save_best_only=False,save_weights_only=False)\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=10,verbose=1,min_lr=0.0001)\n",
    "\n",
    "\n",
    "# history_train_v2 = model_v2.fit(\n",
    "#                     train_dataset,\n",
    "#                     epochs=10,\n",
    "#                     steps_per_epoch=5,\n",
    "#                     validation_data=val_dataset,\n",
    "#                     validation_steps=VALIDATION_STEPS\n",
    "# )\n",
    "\n",
    "# # workers=8,\n",
    "# # use_multiprocessing=False,\n",
    "# # callbacks=[reduce_lr, model_check_point_v2])\n",
    "# model_v2.save('../model/model_mb_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0rOTSwJ4cUX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Add a global average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a classification layer with softmax activation\n",
    "predictions = Dense(10, activation='softmax')(x)  # Assuming 10 classes for CIFAR-10 dataset\n",
    "\n",
    "# Combine the base model with the custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=10,verbose=1,min_lr=0.0001)\n",
    "model_check_point_v2 = ModelCheckpoint(filepath='../model/model_mb_v2.hdf5',monitor='val_loss',verbose=1,save_best_only=False,save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 03:22:54.256025: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [6442]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 03:22:54.256637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [6442]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-25 03:23:13.550128: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 986 of 1000\n",
      "2024-06-25 03:23:13.693940: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2024-06-25 03:23:15.025541: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.2.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2024-06-25 03:23:15.026873: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1068 : UNIMPLEMENTED: DNN library is not found.\n",
      "2024-06-25 03:23:15.026931: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node model/Conv1/Conv2D}}]]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/Conv1/Conv2D' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_22722/2033799493.py\", line 5, in <module>\n      model.fit(train_dataset,\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/Conv1/Conv2D'\nDNN library is not found.\n\t [[{{node model/Conv1/Conv2D}}]] [Op:__inference_train_function_18758]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      3\u001b[0m VALIDATION_STEPS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m980\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVALIDATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_check_point_v2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/model_mb_v2_2.hdf5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/Conv1/Conv2D' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/tmp/ipykernel_22722/2033799493.py\", line 5, in <module>\n      model.fit(train_dataset,\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/Conv1/Conv2D'\nDNN library is not found.\n\t [[{{node model/Conv1/Conv2D}}]] [Op:__inference_train_function_18758]"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 32\n",
    "VALIDATION_STEPS = 980 // 32\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=epochs,\n",
    "          steps_per_epoch=200,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps = VALIDATION_STEPS,\n",
    "          callbacks=[early_stopping, reduce_lr, model_check_point_v2])\n",
    "\n",
    "model.save('../model/model_mb_v2_2.hdf5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('../model/model_mb_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# from collections import defaultdict\n",
    "# import os\n",
    "# import re\n",
    "# import random\n",
    "\n",
    "\n",
    "# # Initialize the storage client\n",
    "# storage_client = storage.Client()\n",
    "\n",
    "# # Set bucket name from environment variable\n",
    "# bucket_name = os.environ[\"BUCKET\"]\n",
    "# bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# image_folder = \"test\"\n",
    "\n",
    "# # List all image files in the specified folder\n",
    "# blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "# image_urls = []\n",
    "# labels = []\n",
    "# images = []\n",
    "\n",
    "\n",
    "# # Dictionary to keep track of image counts per label\n",
    "# label_counts = defaultdict(int)\n",
    "\n",
    "# # Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(600, 700))\n",
    "\n",
    "# # Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "# for blob in blobs:\n",
    "#     if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('test/tomato'):\n",
    "#         label = blob.name.replace('test/', '')\n",
    "#         if label_counts[label] < label_limits[label]:\n",
    "#             image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "#             labels.append(label)\n",
    "#             label_counts[label] += 1\n",
    "\n",
    "# print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# # Print the count of images for each label\n",
    "# for label, count in label_counts.items():\n",
    "#     print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Helper function to download and preprocess an image\n",
    "# def download_and_preprocess_image(url):\n",
    "#     # Download image\n",
    "#     image_blob = bucket.blob(url.replace(f\"gs://{bucket_name}/\", \"\"))\n",
    "#     image_content = image_blob.download_as_bytes()\n",
    "    \n",
    "#     # Load image\n",
    "#     img = image.load_img(BytesIO(image_content), target_size=(224, 224))\n",
    "#     img_array = image.img_to_array(img)\n",
    "#     img_array = np.expand_dims(img_array, axis=0)\n",
    "#     img_array /= 255.0\n",
    "#     return img_array\n",
    "\n",
    "# # Download and preprocess test images\n",
    "# test_images = np.vstack([download_and_preprocess_image(url) for url in image_urls])\n",
    "\n",
    "# # Load your model (assuming it's a Keras model)\n",
    "# model = tf.keras.models.load_model('../model/model_mb_v2.hdf5')\n",
    "\n",
    "# # Make predictions\n",
    "# predictions = model.predict(test_images)\n",
    "\n",
    "# # Print predictions\n",
    "# for url, prediction in zip(image_urls, predictions):\n",
    "#     print(f\"Image URL: {url}, Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MobileNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
