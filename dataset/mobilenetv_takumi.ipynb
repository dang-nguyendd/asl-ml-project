{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4N88SJ0PXWY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 08:16:52.238591: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def relu6(inputs):\n",
    "    '''\n",
    "        Performs the ReLU6 activation function for the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs for the activation function\n",
    "        Return:\n",
    "            Min value between the value of the regular ReLU function and 6\n",
    "    '''\n",
    "    \n",
    "    return K.relu(inputs,max_value=6)\n",
    "\n",
    "def bottleneck(inputs, t, alpha, num_filters, kernel_sz=(3,3),stride=(1,1),pad='same',residual=False,dropout=False,dropout_perc=0.1):    \n",
    "    '''\n",
    "        Performs the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs\n",
    "            t: the value used to increase the number of filters of the expansion stage\n",
    "            alpha: width multiplier that controls the number of filters of the output tensor\n",
    "            num_filters: number of filters of the output tensor\n",
    "            kernel_sz = kernel size of the filter\n",
    "            stride: stride of the kernel\n",
    "            pad: padding of the filter\n",
    "            residual: parameter that determine the sum of the input and output of the bottleneck stage\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero\n",
    "        Return:\n",
    "            x: the result of the bottleneck stage\n",
    "    '''    \n",
    "    \n",
    "    # Get the index of the input 4D tensor that represents the number of channels of the image\n",
    "    # -1 can also represent the last element of the tensor\n",
    "    channel_idx = 1 if K.image_data_format == 'channels_first' else -1\n",
    "    \n",
    "    # Number of filters for the expansion convolution\n",
    "    num_filters_exp = K.int_shape(inputs)[channel_idx] * t    \n",
    "    \n",
    "    # Number of filters of the projection convolution\n",
    "    num_filters_proj = int(num_filters * alpha)\n",
    "    \n",
    "    # Expansion layer\n",
    "    x = Conv2D(filters=num_filters_exp,kernel_size=(1,1),strides=(1,1),padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Depthwise convolution\n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Projection convolution\n",
    "    x = Conv2D(filters=num_filters_proj,kernel_size=(1,1),strides=(1,1),padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if (residual == True):\n",
    "        x = Add()([x,inputs])\n",
    "        \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def depthwise_block(inputs,stride,kernel_sz=(3,3),pad='same'):\n",
    "    '''\n",
    "        Function that performs the depthwise convolution\n",
    "        Inputs:\n",
    "            inputs:    the input shape of the depthwise convolution\n",
    "            kernel_sz: a tuple that indicates the size of the filtering kernel\n",
    "            stride:    a tuple that indicates the strides of the kernel\n",
    "        Return:\n",
    "            x: the result of the depthwise convolution\n",
    "    '''\n",
    "        \n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def pointwise_block(inputs,num_filters,alpha,kernel_sz=(1,1),stride=(1,1),pad='same',dropout=False,dropout_perc=0.1):\n",
    "    '''\n",
    "        Function that performs the pointwise convolution\n",
    "        Inputs:\n",
    "            inputs:      the input shape of the depthwise convolution\n",
    "            num_filters: number of filters to be used in the convolution\n",
    "            kernel_sz:   a tuple that indicates the size of the filtering kernel\n",
    "            stride:      a tuple that indicates the strides of the kernel\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero            \n",
    "        Return:\n",
    "            x: the result of the pointwise convolution\n",
    "    '''    \n",
    "    \n",
    "    # Number of filters based on width multiplier reported in the original paper\n",
    "    n_fil = int(num_filters * alpha)    \n",
    "    \n",
    "    x = Conv2D(filters=n_fil,kernel_size=kernel_sz,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNetV2_ex(input_shape, num_units, filters=32, kernel_sz=(3,3),stride=(2,2),alp=1,ro=1,dropout_perc=0.1):\n",
    "    input_shape = (int(input_shape[0] * ro), int(input_shape[1] * ro), input_shape[2])\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Regular convolution\n",
    "    x = Conv2D(filters=filters,kernel_size=kernel_sz,strides=stride)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    x = Dropout(dropout_perc)(x)\n",
    "\n",
    "    # First bottleneck convolution\n",
    "    x = bottleneck(x,t=1,alpha=alp,num_filters=16,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "\n",
    "    # Second bottleneck convolution (peformed 2 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(2,2),dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Third bottleneck convolution (peformed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fourth bottleneck convolution (performed 4 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fifth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Sixth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Seventh bottleneck convolution (performed 1 time)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=320,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Eigth layer (regular convolution)\n",
    "    x = Conv2D(filters=1280, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    # Pooling layer\n",
    "    # Pooling size correction due to the resolution multiplier parameter\n",
    "    pool_size = int(np.round(7*ro))\n",
    "    x = AveragePooling2D(padding='valid',pool_size=(pool_size,pool_size),strides=(1,1))(x)    \n",
    "    \n",
    "    x = Conv2D(filters=num_units,kernel_size=(1,1),strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    output = Reshape((num_units,))(Activation(activation='softmax')(x))\n",
    "    \n",
    "    return Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rO1uBKlDSMXH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "ro = 1\n",
    "img_size = 224\n",
    "target_sz = int(img_size * ro)\n",
    "batch_sz = 32\n",
    "epo = 100\n",
    "\n",
    "# image_generator = ImageDataGenerator(rotation_range=15,\n",
    "#                                       rescale=1./255,\n",
    "#                                       shear_range=0.2,\n",
    "#                                       zoom_range=0.1,\n",
    "#                                       horizontal_flip=True,\n",
    "#                                       fill_mode='nearest')\n",
    "# train_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Treinamento',\n",
    "#                                                      target_size=(target_sz,target_sz),\n",
    "#                                                      color_mode='rgb',\n",
    "#                                                      batch_size=batch_sz,\n",
    "#                                                      class_mode='categorical',\n",
    "#                                                      shuffle=True)\n",
    "\n",
    "# image_generator = ImageDataGenerator(rescale=1./255)\n",
    "# test_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Teste',\n",
    "#                                                      target_size=(target_sz,target_sz),\n",
    "#                                                      color_mode='rgb',\n",
    "#                                                      batch_size=batch_sz,\n",
    "#                                                      class_mode='categorical',\n",
    "#                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18345 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 1702\n",
      "Label: Tomato___Early_blight, Number of Images: 1920\n",
      "Label: Tomato___Late_blight, Number of Images: 1851\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 1882\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 1745\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 1741\n",
      "Label: Tomato___Target_Spot, Number of Images: 1827\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 1961\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 1790\n",
      "Label: Tomato___healthy, Number of Images: 1926\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"train\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'train/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(600, 700))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('train/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def load_dataset(csv_of_filenames, batch_size, training=True):\n",
    "#     dataset = (\n",
    "#         tf.data.TextLineDataset(filenames=csv_of_filenames)\n",
    "#         .map(decode_csv)\n",
    "#         .cache()\n",
    "#     )\n",
    "\n",
    "#     if training:\n",
    "#         dataset = (\n",
    "#             dataset.map(read_and_preprocess_with_augment)\n",
    "#             .shuffle(SHUFFLE_BUFFER)\n",
    "#             .repeat(count=None)\n",
    "#         )  # Indefinately.\n",
    "#     else:\n",
    "#         dataset = dataset.map(read_and_preprocess).repeat(\n",
    "#             count=1\n",
    "#         )  # Each photo used once.\n",
    "\n",
    "#     # Prefetch prepares the next set of batches while current batch is in use.\n",
    "#     return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# def load_data_from_gcs(image_urls):\n",
    "#     for url in image_urls[:10]:\n",
    "#         images.append(preprocess_image(url))\n",
    "#     return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images = load_data_from_gcs(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4585 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 425\n",
      "Label: Tomato___Early_blight, Number of Images: 480\n",
      "Label: Tomato___Late_blight, Number of Images: 463\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 470\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 436\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 435\n",
      "Label: Tomato___Target_Spot, Number of Images: 457\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 490\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 448\n",
      "Label: Tomato___healthy, Number of Images: 481\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"valid\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "val_image_urls = []\n",
    "val_labels = []\n",
    "val_images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'valid/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(90, 105))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('valid/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        val_image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        val_labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(val_image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are 10 available classes: ['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
      " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
      " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
      " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
      " 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "CLASS_NAMES = np.array(\n",
    "    [\"Tomato___Bacterial_spot\", \n",
    "\"Tomato___Early_blight\", \n",
    "\"Tomato___Late_blight\",\n",
    "\"Tomato___Leaf_Mold\",\n",
    "\"Tomato___Septoria_leaf_spot\",\n",
    "\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "\"Tomato___Target_Spot\",\n",
    "\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "\"Tomato___Tomato_mosaic_virus\",\n",
    "\"Tomato___healthy\"]\n",
    ")\n",
    "\n",
    "print(f\"These are {len(CLASS_NAMES)} available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "SHUFFLE_BUFFER = 1000 \n",
    "batch_size = 32\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def read_and_preprocess(file_path, label_str, random_augment=False):\n",
    "    if random_augment:\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.random_brightness(image, MAX_DELTA)\n",
    "        image = tf.image.random_contrast(image, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "        image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    else: \n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    label = tf.math.equal(CLASS_NAMES, label_str)\n",
    "    return image, label\n",
    "\n",
    "def read_and_preprocess_with_augment(file_path, label_str):\n",
    "    return read_and_preprocess(file_path, label_str, random_augment=True)\n",
    "\n",
    "def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls))\n",
    "    if training:\n",
    "        dataset = dataset.map(read_and_preprocess_with_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "        dataset = dataset.repeat()\n",
    "    else:\n",
    "        dataset = dataset.map(read_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat(1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dataset = load_dataset(image_urls, labels, batch_size, training=True)\n",
    "val_dataset = load_dataset(val_image_urls, val_labels, batch_size, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 08:20:27.678924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [18345]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 08:20:27.679434: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [18345]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 08:20:37.718047: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 726 of 1000\n",
      "2024-06-25 08:20:42.745609: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "tf.Tensor(\n",
      "[[[[0.4254902  0.4053221  0.37420967]\n",
      "   [0.45852342 0.43549418 0.40334132]\n",
      "   [0.4782313  0.45686275 0.42314926]\n",
      "   ...\n",
      "   [0.53353345 0.5142057  0.4867547 ]\n",
      "   [0.53333336 0.5137855  0.48633453]\n",
      "   [0.53333336 0.5137255  0.4862745 ]]\n",
      "\n",
      "  [[0.42358944 0.39983994 0.37210885]\n",
      "   [0.45188075 0.4252701  0.39407766]\n",
      "   [0.44903964 0.4232293  0.3926971 ]\n",
      "   ...\n",
      "   [0.5397358  0.5235093  0.49605834]\n",
      "   [0.537535   0.51924765 0.4917967 ]\n",
      "   [0.53909564 0.5195478  0.49209684]]\n",
      "\n",
      "  [[0.43437374 0.4096439  0.38191277]\n",
      "   [0.46158463 0.43885556 0.40832335]\n",
      "   [0.43435374 0.4090236  0.38107243]\n",
      "   ...\n",
      "   [0.5506402  0.5328331  0.5053821 ]\n",
      "   [0.5534414  0.53721493 0.50866354]\n",
      "   [0.56292534 0.5435975  0.5160466 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.467427   0.45192075 0.42839134]\n",
      "   [0.47791108 0.46474585 0.44121644]\n",
      "   [0.4764104  0.46234477 0.43881536]\n",
      "   ...\n",
      "   [0.5487994  0.54257697 0.5160263 ]\n",
      "   [0.5448178  0.5375149  0.51314515]\n",
      "   [0.542937   0.53509384 0.510264  ]]\n",
      "\n",
      "  [[0.47911173 0.46656674 0.44303733]\n",
      "   [0.4793518  0.46758708 0.44405767]\n",
      "   [0.47140855 0.4582433  0.4347139 ]\n",
      "   ...\n",
      "   [0.54231685 0.535014   0.5109443 ]\n",
      "   [0.5413565  0.53369343 0.50998396]\n",
      "   [0.54039615 0.5354143  0.5090236 ]]\n",
      "\n",
      "  [[0.50030047 0.48827562 0.4647462 ]\n",
      "   [0.49445805 0.4790518  0.45630273]\n",
      "   [0.4839338  0.46972808 0.44853967]\n",
      "   ...\n",
      "   [0.5349339  0.5270908  0.5035614 ]\n",
      "   [0.5432574  0.5382754  0.51188487]\n",
      "   [0.5515809  0.5442579  0.5168269 ]]]\n",
      "\n",
      "\n",
      " [[[0.49839935 0.49447778 0.4787915 ]\n",
      "   [0.50178075 0.49869952 0.48295322]\n",
      "   [0.5165667  0.5164666  0.49929973]\n",
      "   ...\n",
      "   [0.5007403  0.4952381  0.46918762]\n",
      "   [0.4992197  0.49215683 0.46492594]\n",
      "   [0.49915966 0.49131653 0.46414563]]\n",
      "\n",
      "  [[0.502421   0.49927974 0.48359346]\n",
      "   [0.51896757 0.5158863  0.49935973]\n",
      "   [0.51164466 0.51054424 0.49203682]\n",
      "   ...\n",
      "   [0.5142857  0.50644255 0.48093235]\n",
      "   [0.5118647  0.5040216  0.47983193]\n",
      "   [0.5112045  0.50336134 0.47983193]]\n",
      "\n",
      "  [[0.4982993  0.49681872 0.48113245]\n",
      "   [0.51880753 0.51652664 0.5003001 ]\n",
      "   [0.5037415  0.5023409  0.48413363]\n",
      "   ...\n",
      "   [0.50756305 0.4997199  0.47619048]\n",
      "   [0.5086635  0.50082034 0.47619048]\n",
      "   [0.5089636  0.50112045 0.47619048]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5764706  0.5764706  0.5568628 ]\n",
      "   [0.5764706  0.5764706  0.5568628 ]\n",
      "   [0.577371   0.5764706  0.55776316]\n",
      "   ...\n",
      "   [0.5812925  0.5739495  0.54739887]\n",
      "   [0.5831932  0.5773309  0.5498799 ]\n",
      "   [0.5831932  0.5755301  0.54807913]]\n",
      "\n",
      "  [[0.5795519  0.5795519  0.56302524]\n",
      "   [0.5795519  0.5795519  0.56302524]\n",
      "   [0.5809524  0.5795519  0.56332535]\n",
      "   ...\n",
      "   [0.5820729  0.5742298  0.5490597 ]\n",
      "   [0.58347344 0.57629055 0.55192083]\n",
      "   [0.58347344 0.57569027 0.55132055]]\n",
      "\n",
      "  [[0.5876752  0.58403367 0.5683474 ]\n",
      "   [0.5876752  0.58403367 0.5683474 ]\n",
      "   [0.5877752  0.58533424 0.5683474 ]\n",
      "   ...\n",
      "   [0.59019625 0.5823531  0.5550822 ]\n",
      "   [0.5915968  0.58661485 0.55944395]\n",
      "   [0.5915968  0.5873952  0.56022424]]]\n",
      "\n",
      "\n",
      " [[[0.4580232  0.4695278  0.42272907]\n",
      "   [0.44969988 0.45782313 0.41440576]\n",
      "   [0.44277713 0.4522009  0.407483  ]\n",
      "   ...\n",
      "   [0.40970385 0.41362542 0.4018607 ]\n",
      "   [0.41434577 0.41826734 0.40650263]\n",
      "   [0.42298934 0.4269109  0.4151462 ]]\n",
      "\n",
      "  [[0.45580232 0.46756703 0.4205082 ]\n",
      "   [0.45712286 0.46888757 0.42182875]\n",
      "   [0.46080434 0.47256905 0.4255102 ]\n",
      "   ...\n",
      "   [0.4182073  0.42212886 0.41036415]\n",
      "   [0.419968   0.42388958 0.41212487]\n",
      "   [0.4233094  0.42723095 0.41546625]]\n",
      "\n",
      "  [[0.4633053  0.47376952 0.4267107 ]\n",
      "   [0.4694678  0.48093238 0.43387356]\n",
      "   [0.4820128  0.49237695 0.44531813]\n",
      "   ...\n",
      "   [0.4297519  0.43367347 0.42190877]\n",
      "   [0.42717084 0.4310924  0.4193277 ]\n",
      "   [0.42372945 0.42765102 0.4158863 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.30008    0.31968784 0.29615843]\n",
      "   [0.30954388 0.32915172 0.3061625 ]\n",
      "   [0.31512603 0.33473387 0.31282517]\n",
      "   ...\n",
      "   [0.27709067 0.2775908  0.23927549]\n",
      "   [0.26692668 0.2689075  0.22999191]\n",
      "   [0.2715287  0.27404973 0.23613454]]\n",
      "\n",
      "  [[0.29887956 0.3184874  0.294958  ]\n",
      "   [0.31064427 0.3302521  0.30690274]\n",
      "   [0.31182468 0.33143255 0.3084433 ]\n",
      "   ...\n",
      "   [0.27200863 0.27200863 0.2347738 ]\n",
      "   [0.2686075  0.2692677  0.2307123 ]\n",
      "   [0.2790519  0.2798922  0.24353774]]\n",
      "\n",
      "  [[0.29497793 0.31458578 0.29105636]\n",
      "   [0.3025809  0.32218874 0.29865932]\n",
      "   [0.29869926 0.3183071  0.2947777 ]\n",
      "   ...\n",
      "   [0.2646257  0.2646257  0.22689053]\n",
      "   [0.27182883 0.27182883 0.23553438]\n",
      "   [0.2919173  0.2919173  0.2532217 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.5195878  0.49633855 0.5240496 ]\n",
      "   [0.5297319  0.510124   0.53757507]\n",
      "   [0.545078   0.5241696  0.5529211 ]\n",
      "   ...\n",
      "   [0.38995567 0.35858312 0.3742694 ]\n",
      "   [0.3711884  0.33981586 0.35572222]\n",
      "   [0.3694278  0.33805525 0.3537615 ]]\n",
      "\n",
      "  [[0.5407763  0.517467   0.5485594 ]\n",
      "   [0.542497   0.5222289  0.5496799 ]\n",
      "   [0.5405762  0.52066827 0.54811925]\n",
      "   ...\n",
      "   [0.37384957 0.34247702 0.3581633 ]\n",
      "   [0.37777114 0.3463986  0.36450586]\n",
      "   [0.38337347 0.3520009  0.3679072 ]]\n",
      "\n",
      "  [[0.55116045 0.52773106 0.557523  ]\n",
      "   [0.5448379  0.5229492  0.5507003 ]\n",
      "   [0.537475   0.51556623 0.5439176 ]\n",
      "   ...\n",
      "   [0.40670282 0.37533027 0.3924171 ]\n",
      "   [0.4090036  0.3765306  0.39361742]\n",
      "   [0.40086022 0.36808708 0.38517395]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5282911  0.49037594 0.48889533]\n",
      "   [0.5235692  0.48489374 0.4823727 ]\n",
      "   [0.51960754 0.4829129  0.48039186]\n",
      "   ...\n",
      "   [0.33165103 0.2792701  0.27534854]\n",
      "   [0.261363   0.20810169 0.20418012]\n",
      "   [0.30244046 0.24893904 0.24501747]]\n",
      "\n",
      "  [[0.5063224  0.46710673 0.46418554]\n",
      "   [0.50804317 0.46900755 0.46816725]\n",
      "   [0.5067227  0.46834728 0.46750697]\n",
      "   ...\n",
      "   [0.34365776 0.29267737 0.2887558 ]\n",
      "   [0.31914824 0.26750764 0.26358607]\n",
      "   [0.3163071  0.2616252  0.25770363]]\n",
      "\n",
      "  [[0.5246102  0.488776   0.48513454]\n",
      "   [0.5373555  0.49813986 0.49735954]\n",
      "   [0.5472397  0.50802404 0.50568295]\n",
      "   ...\n",
      "   [0.3199275  0.2676466  0.26372504]\n",
      "   [0.33257285 0.27873123 0.27480966]\n",
      "   [0.27926964 0.2243877  0.22046614]]]\n",
      "\n",
      "\n",
      " [[[0.82663065 0.8386555  0.8072829 ]\n",
      "   [0.8269508  0.842357   0.81098443]\n",
      "   [0.8272709  0.8426771  0.81130457]\n",
      "   ...\n",
      "   [0.77629054 0.76060426 0.77236897]\n",
      "   [0.7733293  0.75764304 0.76940775]\n",
      "   [0.77254903 0.75686276 0.76862746]]\n",
      "\n",
      "  [[0.8134454  0.8252101  0.79383755]\n",
      "   [0.8181072  0.8298719  0.79849935]\n",
      "   [0.8235494  0.8353141  0.80394155]\n",
      "   ...\n",
      "   [0.77394956 0.7582633  0.770028  ]\n",
      "   [0.7718888  0.75620246 0.76796716]\n",
      "   [0.7717087  0.75602245 0.76778716]]\n",
      "\n",
      "  [[0.80420166 0.81596637 0.7845938 ]\n",
      "   [0.8095238  0.8212885  0.789916  ]\n",
      "   [0.8179872  0.8297519  0.79837936]\n",
      "   ...\n",
      "   [0.7744497  0.75876343 0.77052814]\n",
      "   [0.7705682  0.7548819  0.7666466 ]\n",
      "   [0.7687274  0.75304115 0.76480585]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.935194   0.935194   0.9260504 ]\n",
      "   [0.91960776 0.9204481  0.9117646 ]\n",
      "   [0.90448177 0.90840334 0.89663863]\n",
      "   ...\n",
      "   [0.35636258 0.34459788 0.3289116 ]\n",
      "   [0.35796317 0.34619847 0.3305122 ]\n",
      "   [0.3619048  0.3501401  0.33445382]]\n",
      "\n",
      "  [[0.9203881  0.9234693  0.91254497]\n",
      "   [0.91028404 0.91354537 0.9024409 ]\n",
      "   [0.90110046 0.905022   0.8932573 ]\n",
      "   ...\n",
      "   [0.35796317 0.34619847 0.3305122 ]\n",
      "   [0.35686275 0.34509805 0.32941177]\n",
      "   [0.35478184 0.34301713 0.32733086]]\n",
      "\n",
      "  [[0.9027809  0.90670246 0.89493775]\n",
      "   [0.8987593  0.9019006  0.8901359 ]\n",
      "   [0.8995198  0.9011004  0.8893357 ]\n",
      "   ...\n",
      "   [0.3619048  0.3501401  0.33445382]\n",
      "   [0.35478184 0.34301713 0.32733086]\n",
      "   [0.3495797  0.337815   0.3221287 ]]]\n",
      "\n",
      "\n",
      " [[[0.12989195 0.13773508 0.12204883]\n",
      "   [0.15662265 0.16446579 0.14877951]\n",
      "   [0.1592837  0.16712683 0.15144056]\n",
      "   ...\n",
      "   [0.35668266 0.34099638 0.37236893]\n",
      "   [0.35658264 0.34089637 0.37226892]\n",
      "   [0.35658264 0.34089637 0.37226892]]\n",
      "\n",
      "  [[0.15730292 0.16436574 0.14867947]\n",
      "   [0.16546617 0.17330931 0.15762304]\n",
      "   [0.15406162 0.16190475 0.14621848]\n",
      "   ...\n",
      "   [0.3543417  0.3386554  0.37002796]\n",
      "   [0.3522809  0.33593437 0.3679672 ]\n",
      "   [0.35210085 0.3355742  0.36778712]]\n",
      "\n",
      "  [[0.12464986 0.13015206 0.11446578]\n",
      "   [0.12667067 0.13451381 0.11882753]\n",
      "   [0.11622649 0.12406963 0.10838335]\n",
      "   ...\n",
      "   [0.3543417  0.3386554  0.37002796]\n",
      "   [0.34985992 0.3310924  0.3655462 ]\n",
      "   [0.34901962 0.32941177 0.3647059 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.09309737 0.09161681 0.0798521 ]\n",
      "   [0.08275313 0.0804722  0.0690076 ]\n",
      "   [0.08571412 0.08341322 0.07344923]\n",
      "   ...\n",
      "   [0.4017409  0.39389777 0.36342555]\n",
      "   [0.40166074 0.3938176  0.3638456 ]\n",
      "   [0.39643848 0.38859534 0.36096433]]\n",
      "\n",
      "  [[0.07607026 0.07292897 0.06402543]\n",
      "   [0.07032802 0.06658652 0.05482181]\n",
      "   [0.07064818 0.06726681 0.05690267]\n",
      "   ...\n",
      "   [0.4106243  0.40278116 0.3714086 ]\n",
      "   [0.40542212 0.39757898 0.36620644]\n",
      "   [0.3966385  0.38879538 0.36106434]]\n",
      "\n",
      "  [[0.02088743 0.01696586 0.00910272]\n",
      "   [0.0414361  0.03751453 0.02939135]\n",
      "   [0.05714265 0.05452163 0.04519792]\n",
      "   ...\n",
      "   [0.4104642  0.40262106 0.3712485 ]\n",
      "   [0.39987975 0.39203662 0.36352527]\n",
      "   [0.38935548 0.38151234 0.35065988]]]], shape=(32, 224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 08:20:44.014907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 08:20:44.017471: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "tf.Tensor(\n",
      "[[[[0.38007203 0.34085634 0.33693478]\n",
      "   [0.56656665 0.5273509  0.52342933]\n",
      "   [0.5322329  0.4930172  0.48909563]\n",
      "   ...\n",
      "   [0.6185876  0.5832935  0.5950582 ]\n",
      "   [0.6331133  0.5978192  0.6095839 ]\n",
      "   [0.63921577 0.60392165 0.61568636]]\n",
      "\n",
      "  [[0.44783917 0.4086235  0.40470192]\n",
      "   [0.5597639  0.5205482  0.51662666]\n",
      "   [0.53635454 0.49713886 0.4932173 ]\n",
      "   ...\n",
      "   [0.62386966 0.58857554 0.60034025]\n",
      "   [0.63267314 0.597379   0.60914373]\n",
      "   [0.6370349  0.6017408  0.6135055 ]]\n",
      "\n",
      "  [[0.5323529  0.49313724 0.48921567]\n",
      "   [0.5345338  0.4953181  0.49139655]\n",
      "   [0.50680274 0.46758705 0.4636655 ]\n",
      "   ...\n",
      "   [0.6080632  0.5727691  0.5845338 ]\n",
      "   [0.6084434  0.57314926 0.58491397]\n",
      "   [0.60868347 0.57338935 0.58515406]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5467988  0.5154263  0.50758314]\n",
      "   [0.5560823  0.52470976 0.5168666 ]\n",
      "   [0.56246483 0.5310923  0.52324915]\n",
      "   ...\n",
      "   [0.6278512  0.6043218  0.6121649 ]\n",
      "   [0.63193274 0.6084033  0.61624646]\n",
      "   [0.6340736  0.6105442  0.61838734]]\n",
      "\n",
      "  [[0.56382567 0.5324531  0.52461   ]\n",
      "   [0.5542217  0.52284914 0.515006  ]\n",
      "   [0.5465185  0.51514596 0.5073028 ]\n",
      "   ...\n",
      "   [0.627451   0.6039216  0.6117647 ]\n",
      "   [0.62811124 0.60458183 0.61242497]\n",
      "   [0.6282913  0.6047619  0.61260504]]\n",
      "\n",
      "  [[0.5711685  0.53979594 0.5319528 ]\n",
      "   [0.5535614  0.52218884 0.5143457 ]\n",
      "   [0.5426571  0.51128453 0.5034414 ]\n",
      "   ...\n",
      "   [0.6284915  0.6049621  0.61280525]\n",
      "   [0.63395375 0.61042434 0.6182675 ]\n",
      "   [0.6381155  0.6145861  0.62242925]]]\n",
      "\n",
      "\n",
      " [[[0.51068425 0.4793117  0.47146857]\n",
      "   [0.49996    0.46858746 0.46074432]\n",
      "   [0.47893158 0.447559   0.43971586]\n",
      "   ...\n",
      "   [0.512065   0.47284928 0.46500614]\n",
      "   [0.50812316 0.4689075  0.46106437]\n",
      "   [0.48765472 0.44843903 0.4405959 ]]\n",
      "\n",
      "  [[0.48089236 0.44951978 0.44167665]\n",
      "   [0.4792717  0.44789916 0.44005603]\n",
      "   [0.47679073 0.44541818 0.43757504]\n",
      "   ...\n",
      "   [0.5084234  0.4692077  0.46136457]\n",
      "   [0.5009403  0.4617246  0.45388147]\n",
      "   [0.485594   0.44637832 0.43853518]]\n",
      "\n",
      "  [[0.4912165  0.45984396 0.45200083]\n",
      "   [0.48543417 0.45406163 0.4462185 ]\n",
      "   [0.48465386 0.45328128 0.44543815]\n",
      "   ...\n",
      "   [0.4922169  0.45300123 0.4451581 ]\n",
      "   [0.48875546 0.44953978 0.44169664]\n",
      "   [0.48299313 0.44377744 0.4359343 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.62016803 0.6005602  0.5887955 ]\n",
      "   [0.629972   0.61036414 0.59859943]\n",
      "   [0.64201677 0.6224089  0.6106442 ]\n",
      "   ...\n",
      "   [0.6459383  0.61456573 0.6067226 ]\n",
      "   [0.647619   0.61624646 0.6084033 ]\n",
      "   [0.65210086 0.6207283  0.6128852 ]]\n",
      "\n",
      "  [[0.64151675 0.6219089  0.6101442 ]\n",
      "   [0.64713895 0.6275311  0.6157664 ]\n",
      "   [0.6532414  0.63363355 0.62186885]\n",
      "   ...\n",
      "   [0.6414565  0.61008394 0.6022408 ]\n",
      "   [0.6431373  0.6117647  0.6039216 ]\n",
      "   [0.64761907 0.6162465  0.6084034 ]]\n",
      "\n",
      "  [[0.65072036 0.6311125  0.6193478 ]\n",
      "   [0.65104043 0.6314326  0.6196679 ]\n",
      "   [0.65136045 0.6317526  0.6199879 ]\n",
      "   ...\n",
      "   [0.6369747  0.60560215 0.597759  ]\n",
      "   [0.6386554  0.6072829  0.59943974]\n",
      "   [0.6465187  0.61514616 0.607303  ]]]\n",
      "\n",
      "\n",
      " [[[0.66638654 0.6507003  0.63893557]\n",
      "   [0.66722685 0.6515406  0.6397759 ]\n",
      "   [0.6703081  0.65462184 0.64285713]\n",
      "   ...\n",
      "   [0.659764   0.6440777  0.6479993 ]\n",
      "   [0.66840744 0.65272117 0.65664274]\n",
      "   [0.67340946 0.6577232  0.66164476]]\n",
      "\n",
      "  [[0.6619048  0.64621854 0.63445383]\n",
      "   [0.6627451  0.64705884 0.63529414]\n",
      "   [0.6658264  0.6501401  0.6383754 ]\n",
      "   ...\n",
      "   [0.65688276 0.6411965  0.64511806]\n",
      "   [0.6597439  0.64405763 0.6479792 ]\n",
      "   [0.65944374 0.64375746 0.64767903]]\n",
      "\n",
      "  [[0.6602241  0.6445378  0.6327731 ]\n",
      "   [0.66106445 0.6453782  0.6336134 ]\n",
      "   [0.66414565 0.6484594  0.63669467]\n",
      "   ...\n",
      "   [0.6531012  0.63741493 0.6413365 ]\n",
      "   [0.6479191  0.63223284 0.6361544 ]\n",
      "   [0.6431372  0.62745094 0.6313725 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.48089263 0.44952005 0.4416769 ]\n",
      "   [0.4692477  0.43787515 0.430032  ]\n",
      "   [0.47506994 0.4436974  0.43585426]\n",
      "   ...\n",
      "   [0.47002828 0.45042044 0.4386557 ]\n",
      "   [0.45546204 0.4358542  0.4240895 ]\n",
      "   [0.47637105 0.4567632  0.4449985 ]]\n",
      "\n",
      "  [[0.49407768 0.46270514 0.454862  ]\n",
      "   [0.46160454 0.430232   0.42238885]\n",
      "   [0.45686263 0.42549008 0.41764694]\n",
      "   ...\n",
      "   [0.4775913  0.45798346 0.44621876]\n",
      "   [0.45818308 0.43857524 0.42681053]\n",
      "   [0.47647107 0.45686322 0.44509852]]\n",
      "\n",
      "  [[0.48433354 0.452961   0.44511783]\n",
      "   [0.44403735 0.4126648  0.40482166]\n",
      "   [0.43575397 0.40438142 0.3965383 ]\n",
      "   ...\n",
      "   [0.46002376 0.44041592 0.4286512 ]\n",
      "   [0.43669403 0.41708618 0.40532148]\n",
      "   [0.45124045 0.4316326  0.4198679 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.53585434 0.5397759  0.50840336]\n",
      "   [0.5305322  0.53445375 0.5030812 ]\n",
      "   [0.5216687  0.52559024 0.4942177 ]\n",
      "   ...\n",
      "   [0.520088   0.520088   0.520088  ]\n",
      "   [0.5241497  0.5241497  0.5241497 ]\n",
      "   [0.52493    0.52493    0.52493   ]]\n",
      "\n",
      "  [[0.51960784 0.5235294  0.49215686]\n",
      "   [0.5144658  0.5183874  0.4870148 ]\n",
      "   [0.5078631  0.5117847  0.4804122 ]\n",
      "   ...\n",
      "   [0.5153861  0.5153861  0.5153861 ]\n",
      "   [0.5142857  0.5142857  0.5142857 ]\n",
      "   [0.5142857  0.5142857  0.5142857 ]]\n",
      "\n",
      "  [[0.5163465  0.5202681  0.48889557]\n",
      "   [0.5131653  0.51708686 0.4857143 ]\n",
      "   [0.51008403 0.5140056  0.48263305]\n",
      "   ...\n",
      "   [0.5014606  0.5014606  0.5014606 ]\n",
      "   [0.5041617  0.5041617  0.5041617 ]\n",
      "   [0.5047619  0.5047619  0.5047619 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.23071209 0.23463365 0.21110424]\n",
      "   [0.23329316 0.23721473 0.21368532]\n",
      "   [0.23327321 0.23719478 0.21366537]\n",
      "   ...\n",
      "   [0.3408965  0.34481806 0.3252102 ]\n",
      "   [0.356903   0.36082456 0.3412167 ]\n",
      "   [0.3714289  0.37535048 0.35574263]]\n",
      "\n",
      "  [[0.21500593 0.2189275  0.19539808]\n",
      "   [0.22587034 0.22979191 0.20626248]\n",
      "   [0.22997199 0.23389356 0.21036415]\n",
      "   ...\n",
      "   [0.35462204 0.3585436  0.33893576]\n",
      "   [0.36798736 0.37190893 0.3523011 ]\n",
      "   [0.3846542  0.38857576 0.36896792]]\n",
      "\n",
      "  [[0.21624658 0.22016814 0.19663873]\n",
      "   [0.22963195 0.23355351 0.2100241 ]\n",
      "   [0.23855558 0.24247715 0.21894774]\n",
      "   ...\n",
      "   [0.35096022 0.3548818  0.33527395]\n",
      "   [0.35624227 0.36016384 0.340556  ]\n",
      "   [0.36916757 0.37308913 0.35348126]]]\n",
      "\n",
      "\n",
      " [[[0.59657866 0.59657866 0.6044218 ]\n",
      "   [0.58067226 0.58067226 0.5885154 ]\n",
      "   [0.6000801  0.6000801  0.6079232 ]\n",
      "   ...\n",
      "   [0.45307964 0.4452365  0.44915807]\n",
      "   [0.45888406 0.45104092 0.4549625 ]\n",
      "   [0.5231702  0.51532704 0.5192486 ]]\n",
      "\n",
      "  [[0.6165266  0.6165266  0.62436974]\n",
      "   [0.59119654 0.59119654 0.5990397 ]\n",
      "   [0.58733493 0.58733493 0.59517807]\n",
      "   ...\n",
      "   [0.49127674 0.4834336  0.48735517]\n",
      "   [0.5470792  0.53923607 0.54315764]\n",
      "   [0.40884072 0.40099758 0.40491915]]\n",
      "\n",
      "  [[0.61056423 0.61056423 0.61840737]\n",
      "   [0.5922769  0.5922769  0.60012   ]\n",
      "   [0.5804922  0.5804922  0.58833534]\n",
      "   ...\n",
      "   [0.46812686 0.46028373 0.4642053 ]\n",
      "   [0.45338133 0.4455382  0.44945976]\n",
      "   [0.45734304 0.4494999  0.45342147]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.59893924 0.5950177  0.5793314 ]\n",
      "   [0.6517006  0.64777905 0.6320928 ]\n",
      "   [0.6791718  0.67525023 0.65956396]\n",
      "   ...\n",
      "   [0.46214494 0.44645867 0.43469396]\n",
      "   [0.47529012 0.45960385 0.44783914]\n",
      "   [0.49327746 0.4775912  0.46582648]]\n",
      "\n",
      "  [[0.6032014  0.5992798  0.58359355]\n",
      "   [0.6578832  0.65396166 0.6382754 ]\n",
      "   [0.69543827 0.6915167  0.6758304 ]\n",
      "   ...\n",
      "   [0.4736094  0.4579231  0.4461584 ]\n",
      "   [0.47088835 0.45520207 0.44343737]\n",
      "   [0.4831334  0.46744713 0.45568243]]\n",
      "\n",
      "  [[0.6457791  0.6418575  0.62617123]\n",
      "   [0.67374974 0.6698282  0.6541419 ]\n",
      "   [0.6959784  0.69205683 0.67637056]\n",
      "   ...\n",
      "   [0.48113233 0.46544605 0.45368135]\n",
      "   [0.47422975 0.45854348 0.44677877]\n",
      "   [0.48515433 0.46946806 0.45770335]]]\n",
      "\n",
      "\n",
      " [[[0.54203683 0.5185074  0.52635056]\n",
      "   [0.54017603 0.5166466  0.52448976]\n",
      "   [0.49573827 0.47220886 0.480052  ]\n",
      "   ...\n",
      "   [0.45972335 0.42050767 0.4165861 ]\n",
      "   [0.51596695 0.47675133 0.47282976]\n",
      "   [0.49321648 0.4540008  0.45007923]]\n",
      "\n",
      "  [[0.5904162  0.5668867  0.57472986]\n",
      "   [0.59307724 0.56954783 0.57739097]\n",
      "   [0.5036214  0.48009205 0.4879352 ]\n",
      "   ...\n",
      "   [0.39175642 0.35254073 0.34861916]\n",
      "   [0.44904017 0.4098245  0.40590292]\n",
      "   [0.36552432 0.32630864 0.32238707]]\n",
      "\n",
      "  [[0.50440174 0.48087233 0.48871547]\n",
      "   [0.57028806 0.54675865 0.5546018 ]\n",
      "   [0.50888354 0.48535413 0.49319726]\n",
      "   ...\n",
      "   [0.3974191  0.35820338 0.3542818 ]\n",
      "   [0.46318582 0.42397013 0.42004856]\n",
      "   [0.4351132  0.3958975  0.39197594]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5077232  0.47635064 0.4685075 ]\n",
      "   [0.47865176 0.4472792  0.43943608]\n",
      "   [0.52745134 0.4960788  0.48823568]\n",
      "   ...\n",
      "   [0.3985587  0.35934302 0.35542145]\n",
      "   [0.3868543  0.3476386  0.34371704]\n",
      "   [0.40216082 0.36294514 0.35902357]]\n",
      "\n",
      "  [[0.51444584 0.48307326 0.47523013]\n",
      "   [0.49785924 0.4664867  0.45864356]\n",
      "   [0.54907966 0.5177071  0.509864  ]\n",
      "   ...\n",
      "   [0.37701032 0.33779463 0.33387306]\n",
      "   [0.36814725 0.32893157 0.32501   ]\n",
      "   [0.39912027 0.3599046  0.35598302]]\n",
      "\n",
      "  [[0.5258106  0.49443796 0.48659483]\n",
      "   [0.50108045 0.4697079  0.46186477]\n",
      "   [0.5328128  0.5014402  0.4935971 ]\n",
      "   ...\n",
      "   [0.3867546  0.34753892 0.34361735]\n",
      "   [0.38723537 0.3480197  0.34409812]\n",
      "   [0.43339476 0.39417908 0.3902575 ]]]], shape=(32, 224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for image, label in val_dataset.take(1):\n",
    "    print(image.shape)\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Assuming `dataset` is your tf.data.Dataset object\n",
    "# for img_url, lbl in val_dataset.take(2):\n",
    "#     print(f\"Image shape: {img_url.shape}, Label: {lbl}\")\n",
    "# len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLALd9dcS0MM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Input, Model\n",
    "# from tensorflow.keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "# import numpy as np\n",
    "\n",
    "# VALIDATION_STEPS = 980 // 32\n",
    "\n",
    "# model_v2 = MobileNetV2_ex(input_shape=(224,224,3), num_units=10, alp=1, ro=1, dropout_perc=0.2)\n",
    "\n",
    "# optimizer = Adam(lr=0.001)\n",
    "\n",
    "# model_v2.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model_check_point_v2 = ModelCheckpoint(filepath='../model/model_mb_v2.hdf5',monitor='val_loss',verbose=1,save_best_only=False,save_weights_only=False)\n",
    "\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=10,verbose=1,min_lr=0.0001)\n",
    "\n",
    "\n",
    "# history_train_v2 = model_v2.fit(\n",
    "#                     train_dataset,\n",
    "#                     epochs=10,\n",
    "#                     steps_per_epoch=5,\n",
    "#                     validation_data=val_dataset,\n",
    "#                     validation_steps=VALIDATION_STEPS\n",
    "# )\n",
    "\n",
    "# # workers=8,\n",
    "# # use_multiprocessing=False,\n",
    "# # callbacks=[reduce_lr, model_check_point_v2])\n",
    "# model_v2.save('../model/model_mb_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0rOTSwJ4cUX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Add a global average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a classification layer with softmax activation\n",
    "predictions = Dense(10, activation='softmax')(x)  # 10 classes \n",
    "\n",
    "# Combine the base model with the custom layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=1,verbose=1,min_lr=0.000001)\n",
    "model_check_point_v2 = ModelCheckpoint(filepath='../model/model_mb_v2_3.hdf5',monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 07:10:53.467857: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [18345]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-25 07:10:53.468275: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [18345]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-25 07:11:13.252281: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 990 of 1000\n",
      "2024-06-25 07:11:13.359427: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n",
      "2024-06-25 07:11:14.179335: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2024-06-25 07:11:15.217172: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f57543a28c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-25 07:11:15.217215: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-06-25 07:11:15.217222: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "2024-06-25 07:11:15.223404: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-25 07:11:15.378413: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.8525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 07:14:54.998910: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-06-25 07:14:54.999267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 14.49984, saving model to ../model/model_mb_v2_3.hdf5\n",
      "573/573 [==============================] - 283s 423ms/step - loss: 0.5527 - accuracy: 0.8525 - val_loss: 14.4998 - val_accuracy: 0.1501 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.8630\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "\n",
      "Epoch 2: val_loss did not improve from 14.49984\n",
      "573/573 [==============================] - 263s 460ms/step - loss: 0.4798 - accuracy: 0.8630 - val_loss: 15.3469 - val_accuracy: 0.1514 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.8414\n",
      "Epoch 3: val_loss improved from 14.49984 to 13.05360, saving model to ../model/model_mb_v2_3.hdf5\n",
      "573/573 [==============================] - 227s 397ms/step - loss: 0.5470 - accuracy: 0.8414 - val_loss: 13.0536 - val_accuracy: 0.1866 - lr: 7.0000e-04\n",
      "Epoch 4/10\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.8515\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "\n",
      "Epoch 4: val_loss did not improve from 13.05360\n",
      "573/573 [==============================] - 253s 442ms/step - loss: 0.5043 - accuracy: 0.8515 - val_loss: 13.7654 - val_accuracy: 0.1674 - lr: 7.0000e-04\n",
      "Epoch 5/10\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.8287\n",
      "Epoch 5: val_loss improved from 13.05360 to 9.97078, saving model to ../model/model_mb_v2_3.hdf5\n",
      "573/573 [==============================] - 223s 390ms/step - loss: 0.5988 - accuracy: 0.8287 - val_loss: 9.9708 - val_accuracy: 0.1696 - lr: 4.9000e-04\n",
      "Epoch 6/10\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.5791 - accuracy: 0.8300\n",
      "Epoch 6: val_loss improved from 9.97078 to 8.08434, saving model to ../model/model_mb_v2_3.hdf5\n",
      "573/573 [==============================] - 221s 387ms/step - loss: 0.5791 - accuracy: 0.8300 - val_loss: 8.0843 - val_accuracy: 0.1495 - lr: 4.9000e-04\n",
      "Epoch 7/10\n",
      "464/573 [=======================>......] - ETA: 27s - loss: 0.4908 - accuracy: 0.8594"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "epo_step = len(labels) // 32\n",
    "VALIDATION_STEPS = len(val_labels) // 32\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=epochs,\n",
    "          steps_per_epoch= epo_step,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps = VALIDATION_STEPS,\n",
    "          callbacks=[reduce_lr, model_check_point_v2])\n",
    "\n",
    "model.save('../model/model_mb_v2_3.hdf5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "# model = load_model('../model/model_mb_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# from collections import defaultdict\n",
    "# import os\n",
    "# import re\n",
    "# import random\n",
    "\n",
    "\n",
    "# # Initialize the storage client\n",
    "# storage_client = storage.Client()\n",
    "\n",
    "# # Set bucket name from environment variable\n",
    "# bucket_name = os.environ[\"BUCKET\"]\n",
    "# bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# image_folder = \"test\"\n",
    "\n",
    "# # List all image files in the specified folder\n",
    "# blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "# image_urls = []\n",
    "# labels = []\n",
    "# images = []\n",
    "\n",
    "\n",
    "# # Dictionary to keep track of image counts per label\n",
    "# label_counts = defaultdict(int)\n",
    "\n",
    "# # Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(600, 700))\n",
    "\n",
    "# # Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "# for blob in blobs:\n",
    "#     if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('test/tomato'):\n",
    "#         label = blob.name.replace('test/', '')\n",
    "#         if label_counts[label] < label_limits[label]:\n",
    "#             image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "#             labels.append(label)\n",
    "#             label_counts[label] += 1\n",
    "\n",
    "# print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# # Print the count of images for each label\n",
    "# for label, count in label_counts.items():\n",
    "#     print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from io import BytesIO\n",
    "\n",
    "# # Helper function to download and preprocess an image\n",
    "# def download_and_preprocess_image(url):\n",
    "#     # Download image\n",
    "#     image_blob = bucket.blob(url.replace(f\"gs://{bucket_name}/\", \"\"))\n",
    "#     image_content = image_blob.download_as_bytes()\n",
    "    \n",
    "#     # Load image\n",
    "#     img = image.load_img(BytesIO(image_content), target_size=(224, 224))\n",
    "#     img_array = image.img_to_array(img)\n",
    "#     img_array = np.expand_dims(img_array, axis=0)\n",
    "#     img_array /= 255.0\n",
    "#     return img_array\n",
    "\n",
    "# # Download and preprocess test images\n",
    "# test_images = np.vstack([download_and_preprocess_image(url) for url in image_urls])\n",
    "\n",
    "# # Load your model (assuming it's a Keras model)\n",
    "# model = tf.keras.models.load_model('../model/model_mb_v2.hdf5')\n",
    "\n",
    "# # Make predictions\n",
    "# predictions = model.predict(test_images)\n",
    "\n",
    "# # Print predictions\n",
    "# for url, prediction in zip(image_urls, predictions):\n",
    "#     print(f\"Image URL: {url}, Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MobileNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-12:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
