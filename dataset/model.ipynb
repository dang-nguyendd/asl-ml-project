{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4N88SJ0PXWY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Input, Model\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Reshape, Add, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "\n",
    "def relu6(inputs):\n",
    "    '''\n",
    "        Performs the ReLU6 activation function for the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs for the activation function\n",
    "        Return:\n",
    "            Min value between the value of the regular ReLU function and 6\n",
    "    '''\n",
    "    \n",
    "    return K.relu(inputs,max_value=6)\n",
    "\n",
    "def bottleneck(inputs, t, alpha, num_filters, kernel_sz=(3,3),stride=(1,1),pad='same',residual=False,dropout=False,dropout_perc=0.1):    \n",
    "    '''\n",
    "        Performs the bottleneck stage of the MobileNet V2\n",
    "        Inputs:\n",
    "            inputs: the layer with the inputs\n",
    "            t: the value used to increase the number of filters of the expansion stage\n",
    "            alpha: width multiplier that controls the number of filters of the output tensor\n",
    "            num_filters: number of filters of the output tensor\n",
    "            kernel_sz = kernel size of the filter\n",
    "            stride: stride of the kernel\n",
    "            pad: padding of the filter\n",
    "            residual: parameter that determine the sum of the input and output of the bottleneck stage\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero\n",
    "        Return:\n",
    "            x: the result of the bottleneck stage\n",
    "    '''    \n",
    "    \n",
    "    # Get the index of the input 4D tensor that represents the number of channels of the image\n",
    "    # -1 can also represent the last element of the tensor\n",
    "    channel_idx = 1 if K.image_data_format == 'channels_first' else -1\n",
    "    \n",
    "    # Number of filters for the expansion convolution\n",
    "    num_filters_exp = K.int_shape(inputs)[channel_idx] * t    \n",
    "    \n",
    "    # Number of filters of the projection convolution\n",
    "    num_filters_proj = int(num_filters * alpha)\n",
    "    \n",
    "    # Expansion layer\n",
    "    x = Conv2D(filters=num_filters_exp,kernel_size=(1,1),strides=(1,1),padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Depthwise convolution\n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    \n",
    "    # Projection convolution\n",
    "    x = Conv2D(filters=num_filters_proj,kernel_size=(1,1),strides=(1,1),padding=pad)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if (residual == True):\n",
    "        x = Add()([x,inputs])\n",
    "        \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def depthwise_block(inputs,stride,kernel_sz=(3,3),pad='same'):\n",
    "    '''\n",
    "        Function that performs the depthwise convolution\n",
    "        Inputs:\n",
    "            inputs:    the input shape of the depthwise convolution\n",
    "            kernel_sz: a tuple that indicates the size of the filtering kernel\n",
    "            stride:    a tuple that indicates the strides of the kernel\n",
    "        Return:\n",
    "            x: the result of the depthwise convolution\n",
    "    '''\n",
    "        \n",
    "    x = DepthwiseConv2D(kernel_size=kernel_sz,strides=stride,depth_multiplier=1,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "        \n",
    "    return x\n",
    "\n",
    "def pointwise_block(inputs,num_filters,alpha,kernel_sz=(1,1),stride=(1,1),pad='same',dropout=False,dropout_perc=0.1):\n",
    "    '''\n",
    "        Function that performs the pointwise convolution\n",
    "        Inputs:\n",
    "            inputs:      the input shape of the depthwise convolution\n",
    "            num_filters: number of filters to be used in the convolution\n",
    "            kernel_sz:   a tuple that indicates the size of the filtering kernel\n",
    "            stride:      a tuple that indicates the strides of the kernel\n",
    "            dropout: determine if dropout will be performed \n",
    "            dropout_perc: percentage of neurons that will be set to zero            \n",
    "        Return:\n",
    "            x: the result of the pointwise convolution\n",
    "    '''    \n",
    "    \n",
    "    # Number of filters based on width multiplier reported in the original paper\n",
    "    n_fil = int(num_filters * alpha)    \n",
    "    \n",
    "    x = Conv2D(filters=n_fil,kernel_size=kernel_sz,padding=pad)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    if (dropout == True):\n",
    "      x = Dropout(dropout_perc)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNetV2(input_shape, num_units, filters=32, kernel_sz=(3,3),stride=(2,2),alp=1,ro=1,dropout_perc=0.1):\n",
    "    input_shape = (int(input_shape[0] * ro), int(input_shape[1] * ro), input_shape[2])\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Regular convolution\n",
    "    x = Conv2D(filters=filters,kernel_size=kernel_sz,strides=stride)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu6)(x)\n",
    "    x = Dropout(dropout_perc)(x)\n",
    "\n",
    "    # First bottleneck convolution\n",
    "    x = bottleneck(x,t=1,alpha=alp,num_filters=16,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "\n",
    "    # Second bottleneck convolution (peformed 2 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(2,2),dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=24,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Third bottleneck convolution (peformed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=32,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fourth bottleneck convolution (performed 4 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=64,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Fifth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=96,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Sixth bottleneck convolution (performed 3 times)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(2,2))\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=160,kernel_sz=(3,3),stride=(1,1), residual=True,dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Seventh bottleneck convolution (performed 1 time)\n",
    "    x = bottleneck(x,t=6,alpha=alp,num_filters=320,kernel_sz=(3,3),stride=(1,1),dropout=True,dropout_perc=dropout_perc)\n",
    "    \n",
    "    # Eigth layer (regular convolution)\n",
    "    x = Conv2D(filters=1280, kernel_size=(1,1), strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    # Pooling layer\n",
    "    # Pooling size correction due to the resolution multiplier parameter\n",
    "    pool_size = int(np.round(7*ro))\n",
    "    x = AveragePooling2D(padding='valid',pool_size=(pool_size,pool_size),strides=(1,1))(x)    \n",
    "    \n",
    "    x = Conv2D(filters=num_units,kernel_size=(1,1),strides=(1,1), padding='same')(x)\n",
    "    \n",
    "    output = Reshape((num_units,))(Activation(activation='softmax')(x))\n",
    "    \n",
    "    return Model(inputs,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rO1uBKlDSMXH"
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "ro = 1\n",
    "img_size = 224\n",
    "target_sz = int(img_size * ro)\n",
    "batch_sz = 32\n",
    "epo = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18345 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 1702\n",
      "Label: Tomato___Early_blight, Number of Images: 1920\n",
      "Label: Tomato___Late_blight, Number of Images: 1851\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 1882\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 1745\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 1741\n",
      "Label: Tomato___Target_Spot, Number of Images: 1827\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 1961\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 1790\n",
      "Label: Tomato___healthy, Number of Images: 1926\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"train\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'train/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Collect image URLs and their labels\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('train/tomato'):\n",
    "        image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        labels.append(extract_label(blob.name))\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Count the number of images for each label\n",
    "label_counts = defaultdict(int)\n",
    "for label in labels:\n",
    "    label_counts[label] += 1\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 08:49:01.187252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.200989: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.205331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.209831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.212840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.215761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.538078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.540343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.542382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-21 08:49:01.544390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def preprocess_image(image_url):\n",
    "    image = tf.io.read_file(image_url)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.0  # Normalize to [0, 1]\n",
    "    return image\n",
    "\n",
    "def load_data_from_gcs(image_urls):\n",
    "    for url in image_urls:\n",
    "        images.append(preprocess_image(url))\n",
    "    return images\n",
    "\n",
    "\n",
    "images = load_data_from_gcs(image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
       "array([[[0.41908765, 0.42300922, 0.5053621 ],\n",
       "        [0.49609843, 0.50001997, 0.5823729 ],\n",
       "        [0.48267308, 0.48659465, 0.5689476 ],\n",
       "        ...,\n",
       "        [0.45522168, 0.44345698, 0.5258099 ],\n",
       "        [0.29983875, 0.28807405, 0.370427  ],\n",
       "        [0.47383353, 0.46206883, 0.54442173]],\n",
       "\n",
       "       [[0.53881556, 0.5427371 , 0.62509006],\n",
       "        [0.3688676 , 0.37278917, 0.4551421 ],\n",
       "        [0.5855342 , 0.5894558 , 0.6718087 ],\n",
       "        ...,\n",
       "        [0.40980336, 0.39803866, 0.4803916 ],\n",
       "        [0.31514546, 0.30338076, 0.3857337 ],\n",
       "        [0.57611567, 0.56435096, 0.6467039 ]],\n",
       "\n",
       "       [[0.5138455 , 0.5177671 , 0.60012   ],\n",
       "        [0.69747895, 0.7014005 , 0.78375345],\n",
       "        [0.609964  , 0.6138856 , 0.6962385 ],\n",
       "        ...,\n",
       "        [0.47349125, 0.46172655, 0.54407954],\n",
       "        [0.49165627, 0.47989157, 0.56224453],\n",
       "        [0.46864727, 0.45688257, 0.5392355 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.67132795, 0.6556417 , 0.71054363],\n",
       "        [0.59201515, 0.5763289 , 0.63123083],\n",
       "        [0.56496626, 0.54928   , 0.60418195],\n",
       "        ...,\n",
       "        [0.42965066, 0.39827812, 0.4492585 ],\n",
       "        [0.4192275 , 0.38785496, 0.43883535],\n",
       "        [0.39377668, 0.36240414, 0.41338453]],\n",
       "\n",
       "       [[0.5075218 , 0.49183553, 0.5467375 ],\n",
       "        [0.5925375 , 0.57685125, 0.6317532 ],\n",
       "        [0.60000026, 0.584314  , 0.63921595],\n",
       "        ...,\n",
       "        [0.42839092, 0.39701837, 0.44799876],\n",
       "        [0.37811074, 0.3467382 , 0.39771858],\n",
       "        [0.41466695, 0.3832944 , 0.4342748 ]],\n",
       "\n",
       "       [[0.5159072 , 0.50022095, 0.555123  ],\n",
       "        [0.76801014, 0.75232387, 0.8072258 ],\n",
       "        [0.48999375, 0.47430748, 0.52920943],\n",
       "        ...,\n",
       "        [0.49443948, 0.46306694, 0.5140473 ],\n",
       "        [0.39839897, 0.36702642, 0.4180068 ],\n",
       "        [0.51787174, 0.4864992 , 0.5374796 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[18344]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 09:37:57.956267: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a tf.data.Dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((\u001b[43mimages\u001b[49m, labels))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define your preprocessing and augmentation logic\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(image, label):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "# Define your preprocessing and augmentation logic\n",
    "def preprocess(image, label):\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "dataset = dataset.map(preprocess).batch(batch_sz).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLALd9dcS0MM"
   },
   "outputs": [],
   "source": [
    "model_v2 = MobileNetV2((img_size,img_size,3),num_units=2,alp=alpha,ro=ro,dropout_perc=0.2)\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "\n",
    "model_v2.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model_check_point_v2 = ModelCheckpoint(filepath='../model/model_mb_v2.hdf5',monitor='val_loss',verbose=1,save_best_only=False,save_weights_only=False)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=10,verbose=1,min_lr=0.0001)\n",
    "\n",
    "step_size_train = train_generator.n/train_generator.batch_size\n",
    "step_size_test = test_generator.n/test_generator.batch_size\n",
    "\n",
    "history_train_v2 = model_v2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=epo, validation_data=test_generator,validation_steps=step_size_test,\n",
    "                    workers=8,\n",
    "                    use_multiprocessing=False,\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "model_v2.save('../model/model_mb_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/asl-ml-project/dataset'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JYNBsrwW28mg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hist_df_v1 = pd.DataFrame(history_train_v1.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0rOTSwJ4cUX"
   },
   "outputs": [],
   "source": [
    "with open('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/history_mobilenet_v1.json',mode='w') as f:\n",
    "  hist_df_v1.to_json(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nfUtPMO8png"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "mb_v1 = load_model('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/model_mb_v1_final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsoWLz-397-G"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TXT_VXA-gAH"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_train_v1.history['loss'],c='r',label='Training loss')\n",
    "plt.plot(history_train_v1.history['val_loss'],c='b',label='Validation loss')\n",
    "plt.title('Loss MobileNet V1')\n",
    "plt.legend()\n",
    "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/loss_mbnet_v1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goBR7XBm_hyi"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_train_v1.history['acc'],c='r',label='Training accuracy')\n",
    "plt.plot(history_train_v1.history['val_acc'],c='b',label='Validation accuracy')\n",
    "plt.title('Accuracy MobileNet V1')\n",
    "plt.legend()\n",
    "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/accuracy_mbnet_v1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CR54yhAEKgnT",
    "outputId": "ae2cb1a5-2bce-49b1-8de7-791ef96e26a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 822 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = image_generator.flow_from_directory('/content/gdrive/My Drive/Imagens/Airplane models/Teste',\n",
    "                                                     target_size=(target_sz,target_sz),\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_sz,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--uL4TPQGGk4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "y_pred = mb_v1.predict_generator(test_generator,workers=8,steps=step_size_test)\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_true = test_generator.classes\n",
    "target_names = ['A320','B737']\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true,y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uE44T4URR6bW"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img('/content/gdrive/My Drive/Imagens/Airplane models/Validação/B737/boeing_737_700_566386.jpg',target_size=(target_sz,target_sz))\n",
    "x = image.img_to_array(img)/255.\n",
    "\n",
    "x = x.reshape((-1,target_sz,target_sz,3))\n",
    "\n",
    "pred = mb_v1.predict(x)\n",
    "\n",
    "predicted_class_index = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "prediction = [labels[k] for k in predicted_class_index]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.title('Airplane model: '+str(prediction))\n",
    "plt.savefig('/content/gdrive/My Drive/Colab Notebooks/Experimento 2/B737_4.jpg')\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MobileNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-12:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
