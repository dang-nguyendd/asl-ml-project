{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de50884b-0aea-4f6d-af9f-c6bda86a4c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73baa0a-d06e-4f55-860b-06f31f7d61a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18345 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 1702\n",
      "Label: Tomato___Early_blight, Number of Images: 1920\n",
      "Label: Tomato___Late_blight, Number of Images: 1851\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 1882\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 1745\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 1741\n",
      "Label: Tomato___Target_Spot, Number of Images: 1827\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 1961\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 1790\n",
      "Label: Tomato___healthy, Number of Images: 1926\n"
     ]
    }
   ],
   "source": [
    "# get train \n",
    "\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"train\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'train/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(500, 700))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('train/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b46da771-6bea-4414-ab4f-97111c0ca4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4585 images.\n",
      "Label: Tomato___Bacterial_spot, Number of Images: 425\n",
      "Label: Tomato___Early_blight, Number of Images: 480\n",
      "Label: Tomato___Late_blight, Number of Images: 463\n",
      "Label: Tomato___Leaf_Mold, Number of Images: 470\n",
      "Label: Tomato___Septoria_leaf_spot, Number of Images: 436\n",
      "Label: Tomato___Spider_mites Two-spotted_spider_mite, Number of Images: 435\n",
      "Label: Tomato___Target_Spot, Number of Images: 457\n",
      "Label: Tomato___Tomato_Yellow_Leaf_Curl_Virus, Number of Images: 490\n",
      "Label: Tomato___Tomato_mosaic_virus, Number of Images: 448\n",
      "Label: Tomato___healthy, Number of Images: 481\n"
     ]
    }
   ],
   "source": [
    "# get validation \n",
    "\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"valid\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "val_image_urls = []\n",
    "val_labels = []\n",
    "val_images = []\n",
    "\n",
    "# Function to extract label from the blob name\n",
    "def extract_label(blob_name):\n",
    "    # Example regex to extract label: 'train/category/image.jpg'\n",
    "    match = re.search(r'valid/([^/]+)/.*', blob_name)\n",
    "    return match.group(1) if match else 'unknown'\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "# label_limits = defaultdict(lambda: random.randint(50, 90))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('valid/tomato'):\n",
    "        label = extract_label(blob.name)\n",
    "        # if label_counts[label] < label_limits[label]:\n",
    "        val_image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "        val_labels.append(label)\n",
    "        label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(val_image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6633114-23fa-47c1-b54a-d6357166491d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are 10 available classes: ['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
      " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
      " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
      " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
      " 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "CLASS_NAMES = np.array(\n",
    "    [\"Tomato___Bacterial_spot\", \n",
    "    \"Tomato___Early_blight\", \n",
    "    \"Tomato___Late_blight\",\n",
    "    \"Tomato___Leaf_Mold\",\n",
    "    \"Tomato___Septoria_leaf_spot\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "    \"Tomato___Target_Spot\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "    \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___healthy\"]\n",
    "    )\n",
    "\n",
    "print(f\"These are {len(CLASS_NAMES)} available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47a14ea-80d7-46eb-a852-4950dd29822c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are 10 available classes: ['Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
      " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
      " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
      " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
      " 'Tomato___healthy']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "CLASS_NAMES = np.array(\n",
    "    [\"Tomato___Bacterial_spot\", \n",
    "\"Tomato___Early_blight\", \n",
    "\"Tomato___Late_blight\",\n",
    "\"Tomato___Leaf_Mold\",\n",
    "\"Tomato___Septoria_leaf_spot\",\n",
    "\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "\"Tomato___Target_Spot\",\n",
    "\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "\"Tomato___Tomato_mosaic_virus\",\n",
    "\"Tomato___healthy\"]\n",
    ")\n",
    "\n",
    "print(f\"These are {len(CLASS_NAMES)} available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccd2a03-340a-45b2-a9e2-885faf45f2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 04:31:56.141459: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 04:31:57.948190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:57.950343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:57.959709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:57.961770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:57.963733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:57.965750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.579084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.581288: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.583369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.585420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.587385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.589396: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.609803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.611860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.613848: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.615880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.617871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.619860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 723 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2024-06-27 04:31:58.620874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-27 04:31:58.622820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13664 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "SHUFFLE_BUFFER = 1000 \n",
    "batch_size = 128\n",
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def read_and_preprocess(file_path, label_str, random_augment=False):\n",
    "    if random_augment:\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.random_brightness(image, MAX_DELTA)\n",
    "        image = tf.image.random_contrast(image, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "        image = tf.image.resize(image, [224, 224])  # Adjust to your target size\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    else: \n",
    "        image = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.math.equal(CLASS_NAMES, label_str)\n",
    "    return image, label\n",
    "\n",
    "def read_and_preprocess_with_augment(file_path, label_str):\n",
    "    return read_and_preprocess(file_path, label_str, random_augment=True)\n",
    "\n",
    "# def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls)).cache()\n",
    "#     if training:\n",
    "#         dataset = dataset.shuffle(SHUFFLE_BUFFER)\n",
    "#         dataset = dataset.map(read_and_preprocess_with_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#         dataset = dataset.repeat()\n",
    "#     else:\n",
    "#         dataset = dataset.map(read_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#         dataset = dataset.repeat(1)\n",
    "        \n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#     return dataset\n",
    "\n",
    "def load_dataset(img_urls, lbls, batch_size, training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_urls, lbls)).cache()\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(len(image_urls))\n",
    "        dataset = dataset.map(read_and_preprocess_with_augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat()\n",
    "    else:\n",
    "        dataset = dataset.map(read_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.repeat(1)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "    \n",
    "\n",
    "# Load training and validation datasets\n",
    "train_dataset = load_dataset(image_urls, labels, batch_size, training=True)\n",
    "val_dataset = load_dataset(val_image_urls, val_labels, batch_size, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208b9419-7f73-401f-8c32-4384d66e8dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.9748 - accuracy: 0.6786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 04:37:29.126051: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-06-27 04:37:29.126392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4585]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.74286, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 257s 420ms/step - loss: 0.9748 - accuracy: 0.6786 - val_loss: 0.7429 - val_accuracy: 0.7476 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8165\n",
      "Epoch 2: val_loss improved from 0.74286 to 0.60937, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 230s 402ms/step - loss: 0.5415 - accuracy: 0.8165 - val_loss: 0.6094 - val_accuracy: 0.7933 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.8497\n",
      "Epoch 3: val_loss did not improve from 0.60937\n",
      "573/573 [==============================] - 219s 383ms/step - loss: 0.4394 - accuracy: 0.8497 - val_loss: 0.6235 - val_accuracy: 0.7913 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8772\n",
      "Epoch 4: val_loss did not improve from 0.60937\n",
      "573/573 [==============================] - 219s 383ms/step - loss: 0.3596 - accuracy: 0.8772 - val_loss: 0.7476 - val_accuracy: 0.7579 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8922\n",
      "Epoch 5: val_loss improved from 0.60937 to 0.55386, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 223s 390ms/step - loss: 0.3100 - accuracy: 0.8922 - val_loss: 0.5539 - val_accuracy: 0.8136 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9087\n",
      "Epoch 6: val_loss improved from 0.55386 to 0.49796, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 219s 382ms/step - loss: 0.2726 - accuracy: 0.9087 - val_loss: 0.4980 - val_accuracy: 0.8372 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.9210\n",
      "Epoch 7: val_loss improved from 0.49796 to 0.48883, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 215s 375ms/step - loss: 0.2368 - accuracy: 0.9210 - val_loss: 0.4888 - val_accuracy: 0.8374 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9295\n",
      "Epoch 8: val_loss did not improve from 0.48883\n",
      "573/573 [==============================] - 200s 349ms/step - loss: 0.2079 - accuracy: 0.9295 - val_loss: 0.5162 - val_accuracy: 0.8319 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.9392\n",
      "Epoch 9: val_loss improved from 0.48883 to 0.38403, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 196s 342ms/step - loss: 0.1864 - accuracy: 0.9392 - val_loss: 0.3840 - val_accuracy: 0.8776 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9409\n",
      "Epoch 10: val_loss improved from 0.38403 to 0.33020, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 213s 372ms/step - loss: 0.1709 - accuracy: 0.9409 - val_loss: 0.3302 - val_accuracy: 0.8888 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9455\n",
      "Epoch 11: val_loss improved from 0.33020 to 0.31258, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 168s 294ms/step - loss: 0.1613 - accuracy: 0.9455 - val_loss: 0.3126 - val_accuracy: 0.8999 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.9502\n",
      "Epoch 12: val_loss improved from 0.31258 to 0.30075, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 191s 333ms/step - loss: 0.1447 - accuracy: 0.9502 - val_loss: 0.3007 - val_accuracy: 0.9065 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9541\n",
      "Epoch 13: val_loss improved from 0.30075 to 0.29786, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 217s 379ms/step - loss: 0.1356 - accuracy: 0.9541 - val_loss: 0.2979 - val_accuracy: 0.9049 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.9606\n",
      "Epoch 14: val_loss improved from 0.29786 to 0.25841, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 176s 308ms/step - loss: 0.1207 - accuracy: 0.9606 - val_loss: 0.2584 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9628\n",
      "Epoch 15: val_loss improved from 0.25841 to 0.24704, saving model to ../model/NASNet_cp.hdf5\n",
      "573/573 [==============================] - 193s 337ms/step - loss: 0.1097 - accuracy: 0.9628 - val_loss: 0.2470 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9662\n",
      "Epoch 16: val_loss did not improve from 0.24704\n",
      "573/573 [==============================] - 188s 329ms/step - loss: 0.1060 - accuracy: 0.9662 - val_loss: 0.2855 - val_accuracy: 0.9111 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.0970 - accuracy: 0.9673\n",
      "Epoch 17: val_loss did not improve from 0.24704\n",
      "573/573 [==============================] - 194s 339ms/step - loss: 0.0970 - accuracy: 0.9673 - val_loss: 0.2650 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "573/573 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9704Restoring model weights from the end of the best epoch: 15.\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.24704\n",
      "573/573 [==============================] - 215s 375ms/step - loss: 0.0899 - accuracy: 0.9704 - val_loss: 0.2542 - val_accuracy: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50, NASNetMobile, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "# Define the ResNet50 model\n",
    "base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(CLASS_NAMES), activation='softmax')(x)  # Adjust output layer to number of classes\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of ResNet50 base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0001, weight_decay = 0.0001), \n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(train_dataset,\n",
    "#                     epochs=10,  # Set the number of epochs as needed\n",
    "#                     steps_per_epoch=len(image_urls) // batch_size,\n",
    "#                     validation_data=val_dataset,\n",
    "#                     validation_steps=len(val_image_urls) // batch_size)\n",
    "\n",
    "# Unfreeze some layers and fine-tune the model\n",
    "for layer in base_model.layers[-32:]:  # Unfreeze the last 10 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='../model/NASNet_cp.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=2,verbose=1,min_lr=0.0001)\n",
    "# Continue training with fine-tuning\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=20,  # Continue for more epochs if necessary\n",
    "                         steps_per_epoch=len(image_urls) // batch_size,\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=len(val_image_urls) // batch_size,\n",
    "                         callbacks = [early_stopping,reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02840aa4-283f-4ba9-9d3a-6e9bdc6781ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d_7   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                12810     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,062,381\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Activation, add, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(model_ENB0)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(CLASS_NAMES),activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85e71711-b27f-4328-a890-4ede6cf6b60b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 06:37:07.998206: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - ETA: 0s - loss: 2.3323 - accuracy: 0.0976\n",
      "Epoch 1: val_loss improved from inf to 2.31585, saving model to ../model/EfficientNetB0_cp.hdf5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Continue training with fine-tuning\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m history_fine \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Continue for more epochs if necessary\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_image_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input, Activation, add, Add, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# Create Model\n",
    "model_ENB0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "model_ENB0.trainable = False\n",
    "model_ENB0.summary()\n",
    "model = Sequential()\n",
    "model.add(model_ENB0)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(CLASS_NAMES),activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[-32:]:  # Unfreeze the last 10 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(filepath='../model/EfficientNetB0_cp.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=2,verbose=1,min_lr=0.0001)\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=20,  # Continue for more epochs if necessary\n",
    "                         steps_per_epoch=len(image_urls) // batch_size,\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=len(val_image_urls) // batch_size,\n",
    "                         callbacks = [early_stopping,reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70733dac-df4e-4e3f-b3bf-6e45b76dfe27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 06:46:57.958475: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573/573 [==============================] - ETA: 0s - loss: 2.3341 - accuracy: 0.0985\n",
      "Epoch 1: val_loss improved from inf to 2.33419, saving model to ../model/EfficientNetB0_cp.hdf5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Continue training with fine-tuning\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m history_fine \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_image_urls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "model_ENB0 = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "model_ENB0.trainable = False\n",
    "# model_ENB0.summary()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(model_ENB0)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(CLASS_NAMES), activation=\"softmax\"))\n",
    "# model.summary()\n",
    "\n",
    "for layer in model.layers[-32:]:  # Unfreeze the last 10 layers\n",
    "    layer.trainable = True\n",
    "    \n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath='../model/EfficientNetB0_cp.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=2, verbose=1, min_lr=0.0001)\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=20,\n",
    "                         steps_per_epoch=len(image_urls) // batch_size,\n",
    "                         validation_data=val_dataset,\n",
    "                         validation_steps=len(val_image_urls) // batch_size,\n",
    "                         callbacks=[early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da20033-3cdd-4317-a644-a8448485519e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-12:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
