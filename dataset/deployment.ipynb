{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6baee684-6e4b-443c-8ddb-349020788a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"Tomato___Bacterial_spot\", \n",
    "\"Tomato___Early_blight\", \n",
    "\"Tomato___Late_blight\",\n",
    "\"Tomato___Leaf_Mold\",\n",
    "\"Tomato___Septoria_leaf_spot\",\n",
    "\"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "\"Tomato___Target_Spot\",\n",
    "\"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "\"Tomato___Tomato_mosaic_virus\",\n",
    "\"Tomato___healthy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6ab940-98b7-46d3-b9ff-887cac9e2f22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:39:58.761950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def preprocess(img_bytes):\n",
    "    img = tf.image.decode_jpeg(img_bytes, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_from_jpegfile(filename):\n",
    "    # same code as in 05_create_dataset/jpeg_to_tfrecord.py\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = preprocess(img)\n",
    "    return img\n",
    "\n",
    "def postprocess(pred):\n",
    "    top_prob = tf.math.reduce_max(pred, axis=[1])\n",
    "    pred_label_index = tf.math.argmax(pred, axis=1)\n",
    "    pred_label = tf.gather(tf.convert_to_tensor(CLASSES), pred_label_index)\n",
    "\n",
    "    # custom output\n",
    "    return {\n",
    "        \"probability\": top_prob,\n",
    "        \"plant_type_int\": pred_label_index,\n",
    "        \"plant_type_str\": pred_label,\n",
    "    }\n",
    "\n",
    "\n",
    "# fmt: off\n",
    "# this function receives 1 string value.\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def predict_from_filename(filenames):\n",
    "\n",
    "    # custom pre-process\n",
    "    input_images = tf.map_fn(\n",
    "        read_from_jpegfile, filenames, fn_output_signature=tf.float32\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    batch_pred = model(input_images)  # same as model.predict()\n",
    "\n",
    "    # custom post-process\n",
    "    processed = postprocess(batch_pred)\n",
    "    return processed\n",
    "\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe5ae52-13c5-44b5-b141-cb997912b081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
    "def predict_from_b64(img_bytes):\n",
    "\n",
    "    # custom pre-process\n",
    "    input_images = tf.map_fn(\n",
    "        preprocess, img_bytes, fn_output_signature=tf.float32\n",
    "    )\n",
    "\n",
    "    # model\n",
    "    batch_pred = model(input_images)  # same as model.predict()\n",
    "\n",
    "    # custom post-process\n",
    "    processed = postprocess(batch_pred)\n",
    "    return processed\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624dcdc8-d630-412c-83b2-f913a9953e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:40:00.966142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:00.969881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:00.980630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:00.984126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:00.987392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:00.990690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.605455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.607715: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.609844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.611879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.613881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.615924: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.637083: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.639223: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.641287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.643350: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.645390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.647414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2024-06-26 15:40:01.647939: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-26 15:40:01.650289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13764 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('../model/model_mb_v2_finetuned_5_reducelr.hdf5')\n",
    "\n",
    "# Export model with a new serving function.\n",
    "model.save(\n",
    "    \"../model/export/model_mb_v2_finetuned_5_reducelr_with_signature\",\n",
    "    signatures={\n",
    "        \"serving_default\": predict_from_filename,\n",
    "        \"predict_base64\": predict_from_b64,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3c696e-9cc3-4e1d-9f8a-3cb0b85cec3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['filenames'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: serving_default_filenames:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['plant_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:0\n",
      "  outputs['plant_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:1\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall_1:2\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ../model/export/model_mb_v2_finetuned_5_reducelr_with_signature --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f1b58b-4b29-4b72-85e4-d17bc66cfd30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images.\n",
      "Label: TomatoEarlyBlight1.JPG, Number of Images: 1\n",
      "Label: TomatoEarlyBlight2.JPG, Number of Images: 1\n",
      "Label: TomatoEarlyBlight3.JPG, Number of Images: 1\n",
      "Label: TomatoEarlyBlight4.JPG, Number of Images: 1\n",
      "Label: TomatoEarlyBlight5.JPG, Number of Images: 1\n",
      "Label: TomatoEarlyBlight6.JPG, Number of Images: 1\n",
      "Label: TomatoHealthy1.JPG, Number of Images: 1\n",
      "Label: TomatoHealthy2.JPG, Number of Images: 1\n",
      "Label: TomatoHealthy3.JPG, Number of Images: 1\n",
      "Label: TomatoHealthy4.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus1.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus2.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus3.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus4.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus5.JPG, Number of Images: 1\n",
      "Label: TomatoYellowCurlVirus6.JPG, Number of Images: 1\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "PROJECT = !gcloud config list --format 'value(core.project)'\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT+\"-capstone\"\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION\n",
    "\n",
    "# Initialize the storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Set bucket name from environment variable\n",
    "bucket_name = os.environ[\"BUCKET\"]\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "image_folder = \"test\"\n",
    "\n",
    "# List all image files in the specified folder\n",
    "blobs = bucket.list_blobs(prefix=image_folder)\n",
    "\n",
    "image_urls = []\n",
    "labels = []\n",
    "images = []\n",
    "\n",
    "\n",
    "# Dictionary to keep track of image counts per label\n",
    "label_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to set a random limit for each label\n",
    "label_limits = defaultdict(lambda: random.randint(600, 700))\n",
    "\n",
    "# Collect image URLs and their labels, limit to a random number between 600 and 700 per label\n",
    "for blob in blobs:\n",
    "    if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')) and blob.name.lower().startswith('test/tomato'):\n",
    "        label = blob.name.replace('test/', '')\n",
    "        if label_counts[label] < label_limits[label]:\n",
    "            image_urls.append(f\"gs://{bucket_name}/{blob.name}\")\n",
    "            labels.append(label)\n",
    "            label_counts[label] += 1\n",
    "\n",
    "print(f\"Found {len(image_urls)} images.\")\n",
    "\n",
    "# Print the count of images for each label\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"Label: {label}, Number of Images: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b4368e-4716-406f-9a41-6ce734370dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 15:59:46.202160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant_type_str : [b'Tomato___Early_blight' b'Tomato___Bacterial_spot'\n",
      " b'Tomato___Early_blight' b'Tomato___Early_blight'\n",
      " b'Tomato___Early_blight' b'Tomato___Early_blight' b'Tomato___healthy'\n",
      " b'Tomato___healthy' b'Tomato___healthy' b'Tomato___healthy'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus'\n",
      " b'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n",
      "probability    : [0.9908867  0.96336704 0.99975306 0.99343324 0.9776037  0.9999504\n",
      " 0.99999464 1.         0.9842732  0.9997434  1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "plant_type_int : [1 0 1 1 1 1 9 9 9 9 7 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "serving_fn = tf.keras.models.load_model(\n",
    "    \"../model/export/model_mb_v2_finetuned_5_reducelr_with_signature\"\n",
    ").signatures[\"serving_default\"]\n",
    "\n",
    "pred = serving_fn(tf.convert_to_tensor(image_urls))\n",
    "# print custom outputs\n",
    "for k in pred.keys():\n",
    "    print(f\"{k:15}: {pred[k].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f64eb87-a13a-480e-a821-23acf189a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['img_bytes'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: predict_base64_img_bytes:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['plant_type_int'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "  outputs['plant_type_str'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:1\n",
      "  outputs['probability'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1)\n",
      "      name: StatefulPartitionedCall:2\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir ../model/export/model_mb_v2_finetuned_5_reducelr_with_signature --tag_set serve --signature_def predict_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e766af7f-cc10-4bb5-9bd5-36e701dcdf02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_DISPLAYNAME: model_mb_v2_finetuned_5_reducelr-20240626160223\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "MODEL_DISPLAYNAME = f\"model_mb_v2_finetuned_5_reducelr-{TIMESTAMP}\"\n",
    "\n",
    "print(f\"MODEL_DISPLAYNAME: {MODEL_DISPLAYNAME}\")\n",
    "\n",
    "# from https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "SERVING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-11:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9d44eca-4adb-4af1-bd6f-9161616663f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/fingerprint.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "- [4 files][  3.5 MiB/  3.5 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://../model/export/model_mb_v2_finetuned_5_reducelr_with_signature/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "- [5 files][ 23.0 MiB/ 23.0 MiB]                                                \n",
      "Operation completed over 5 objects/23.0 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -R ../model/export/model_mb_v2_finetuned_5_reducelr_with_signature gs://{BUCKET}/{MODEL_DISPLAYNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a14fb18-d7fc-4456-b8fe-a6bff71d68ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/853791352780/locations/us-central1/endpoints/2952758267601747968/operations/4087578821518163968\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/853791352780/locations/us-central1/endpoints/2952758267601747968\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/853791352780/locations/us-central1/endpoints/2952758267601747968')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/853791352780/locations/us-central1/endpoints/2952758267601747968\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/853791352780/locations/us-central1/endpoints/2952758267601747968/operations/8192046931912949760\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/853791352780/locations/us-central1/endpoints/2952758267601747968\n"
     ]
    }
   ],
   "source": [
    "MACHINE_TYPE = \"n1-standard-4\"\n",
    "\n",
    "endpoint = uploaded_model.deploy(\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "    accelerator_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7433dc2-0614-4780-8a13-163ba70f7092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instances = [{\"filenames\": f} for f in image_urls]\n",
    "# pred = endpoint.predict(instances=instances)\n",
    "\n",
    "# # print custom outputs\n",
    "# for p in pred.predictions:\n",
    "#     for k in p.keys():\n",
    "#         print(f\"{k:15}: {p[k]}\")\n",
    "#     print(\"*\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04332bbc-e90c-4c7b-bd2e-bb74dc9e040b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "token = (\n",
    "    GoogleCredentials.get_application_default().get_access_token().access_token\n",
    ")\n",
    "headers = {\"Authorization\": \"Bearer \" + token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1056238f-090b-4a76-863f-92754813d2b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_DISPLAYNAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[1;32m      3\u001b[0m uploaded_model \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mModel\u001b[38;5;241m.\u001b[39mupload(\n\u001b[0;32m----> 4\u001b[0m     display_name\u001b[38;5;241m=\u001b[39m\u001b[43mMODEL_DISPLAYNAME\u001b[49m,\n\u001b[1;32m      5\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBUCKET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_DISPLAYNAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     serving_container_image_uri\u001b[38;5;241m=\u001b[39mSERVING_CONTAINER_IMAGE_URI,\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_DISPLAYNAME' is not defined"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "uploaded_model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAYNAME,\n",
    "    artifact_uri=f\"gs://{BUCKET}/{MODEL_DISPLAYNAME}\",\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e30d507-1f24-4f91-bc39-86be90bdddd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "def b64encode(filename):\n",
    "    with open(filename, \"rb\") as ifp:\n",
    "        img_bytes = ifp.read()\n",
    "        return base64.b64encode(img_bytes).decode()\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"signature_name\": \"predict_base64\",\n",
    "    \"instances\": [{\"img_bytes\": {\"b64\": b64encode(\"./sample.jpg\")}}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7235937-e1d1-445b-bdad-efb7192bea08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'plant_type_str': 'Tomato___Early_blight',\n",
       "   'probability': 0.990886927,\n",
       "   'plant_type_int': 1}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:rawPredict\".format(\n",
    "    REGION, PROJECT, REGION, endpoint.name\n",
    ")\n",
    "\n",
    "response = requests.post(api, json=data, headers=headers)\n",
    "json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b917608-c730-4dec-86c9-f3967836351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_custom_trained_model_sample(\n",
    "    project=\"853791352780\",\n",
    "    endpoint_id=\"2952758267601747968\",\n",
    "    location=\"us-central1\",\n",
    "    instances={ \"instance_key_1\": \"value\", ...}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-12.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-12:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
